{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Extending Linear Regression (PolynomialFeatures in Sklearn)\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc-depth: 4\n",
    "    jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook you should be able to:\n",
    "\n",
    "- Simulate a nonlinear dataset for regression.\n",
    "- Fit and evaluate a baseline linear regression model.\n",
    "- Use `PolynomialFeatures` to add nonlinear terms and interactions.\n",
    "- Compare model performance across polynomial degrees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Data\n",
    "\n",
    "We simulate two predictors (`x1`, `x2`) from uniform distributions and generate the target `y` from a nonlinear function with added noise. This setup lets us compare linear vs polynomial models on data with known nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.254599</td>\n",
       "      <td>-1.063645</td>\n",
       "      <td>0.295770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.507143</td>\n",
       "      <td>-0.265643</td>\n",
       "      <td>30.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.319939</td>\n",
       "      <td>3.545474</td>\n",
       "      <td>34.523622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986585</td>\n",
       "      <td>-1.599956</td>\n",
       "      <td>-1.109427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.439814</td>\n",
       "      <td>3.696497</td>\n",
       "      <td>49.341010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.440055</td>\n",
       "      <td>-4.118656</td>\n",
       "      <td>-14.395442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.419164</td>\n",
       "      <td>2.767984</td>\n",
       "      <td>43.154083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.661761</td>\n",
       "      <td>3.475476</td>\n",
       "      <td>43.267654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.011150</td>\n",
       "      <td>-3.181823</td>\n",
       "      <td>-9.254211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.080726</td>\n",
       "      <td>-0.696535</td>\n",
       "      <td>11.674644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2          y\n",
       "0 -1.254599 -1.063645   0.295770\n",
       "1  4.507143 -0.265643  30.086577\n",
       "2  2.319939  3.545474  34.523622\n",
       "3  0.986585 -1.599956  -1.109427\n",
       "4 -3.439814  3.696497  49.341010\n",
       "5 -3.440055 -4.118656 -14.395442\n",
       "6 -4.419164  2.767984  43.154083\n",
       "7  3.661761  3.475476  43.267654\n",
       "8  1.011150 -3.181823  -9.254211\n",
       "9  2.080726 -0.696535  11.674644"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "N = 5000\n",
    "\n",
    "# Generate features from uniform distributions\n",
    "x1 = np.random.uniform(-5, 5, N)\n",
    "x2 = np.random.uniform(-5, 5, N)\n",
    "\n",
    "# Define a nonlinear relationship with Gaussian noise\n",
    "y = 1.5 * (x1 ** 2) + 0.5 * (x2 ** 3) + np.random.normal(loc=3, scale=3, size=N)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df.to_csv('nonlinear_dataset.csv', index=False)\n",
    "\n",
    "df.head(10)  # Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target-Feature Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix and target vector\n",
    "X = df[['x1', 'x2']].values\n",
    "y = df['y'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4000, 2)\n",
      "Testing set shape: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Baseline Model (original Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model Performance:\n",
      "Training Set:\n",
      "RMSE: 14.793577191492002\n",
      "R2: 0.6720857612554578\n",
      "\n",
      "Testing Set:\n",
      "RMSE: 14.766591570386126\n",
      "R2: 0.6745129537467693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Fit a baseline linear regression model\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test splits\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_train_pred_baseline = baseline_model.predict(X_train)\n",
    "\n",
    "# Evaluate on test and training sets\n",
    "rmse_baseline = root_mean_squared_error(y_test, y_pred_baseline)\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "rmse_train_baseline = root_mean_squared_error(y_train, y_train_pred_baseline)\n",
    "r2_train_baseline = r2_score(y_train, y_train_pred_baseline)\n",
    "\n",
    "print()\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(\"Training Set:\")\n",
    "print(\"RMSE:\", rmse_train_baseline)\n",
    "print(\"R2:\", r2_train_baseline)\n",
    "print()\n",
    "print(\"Testing Set:\")\n",
    "print(\"RMSE:\", rmse_baseline)\n",
    "print(\"R2:\", r2_baseline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Features with PolynomialFeatures (`degree = 2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create PolynomialFeatures object with degree=2 (includes interaction terms)\n",
    "poly_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Transform the training and testing features\n",
    "X_train_poly_2 = poly_2.fit_transform(X_train)\n",
    "X_test_poly_2 = poly_2.transform(X_test)\n",
    "\n",
    "# Display the transformed feature names\n",
    "print()\n",
    "print(\"Transformed Feature Names:\")\n",
    "print(poly_2.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model with transformed Features (`degree = 2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Model Performance:\n",
      "Training Set:\n",
      "RMSE: 9.762877774623902\n",
      "R2: 0.8571863972474734\n",
      "\n",
      "Testing Set:\n",
      "RMSE: 9.486906471561829\n",
      "R2: 0.8656547173222298\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear regression model on degree-2 polynomial features\n",
    "poly_2_model = LinearRegression()\n",
    "poly_2_model.fit(X_train_poly_2, y_train)\n",
    "\n",
    "# Predict on train and test splits\n",
    "y_pred_poly_2 = poly_2_model.predict(X_test_poly_2)\n",
    "y_train_pred_poly_2 = poly_2_model.predict(X_train_poly_2)\n",
    "\n",
    "# Evaluate on test and training sets\n",
    "rmse_poly_2 = root_mean_squared_error(y_test, y_pred_poly_2)\n",
    "r2_poly_2 = r2_score(y_test, y_pred_poly_2)\n",
    "\n",
    "rmse_train_poly_2 = root_mean_squared_error(y_train, y_train_pred_poly_2)\n",
    "r2_train_poly_2 = r2_score(y_train, y_train_pred_poly_2)\n",
    "\n",
    "print()\n",
    "print(\"Polynomial Model Performance:\")\n",
    "print(\"Training Set:\")\n",
    "print(\"RMSE:\", rmse_train_poly_2)\n",
    "print(\"R2:\", r2_train_poly_2)\n",
    "print()\n",
    "print(\"Testing Set:\")\n",
    "print(\"RMSE:\", rmse_poly_2)\n",
    "print(\"R2:\", r2_poly_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform features with PolynomialFeatures (`degree = 3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2' 'x0^3' 'x0^2 x1' 'x0 x1^2' 'x1^3']\n"
     ]
    }
   ],
   "source": [
    "# Create PolynomialFeatures object with degree=3\n",
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "# Transform the training and testing features\n",
    "X_train_poly_3 = poly_3.fit_transform(X_train)\n",
    "X_test_poly_3 = poly_3.transform(X_test)\n",
    "\n",
    "# Display the transformed feature names\n",
    "print()\n",
    "print(\"Transformed Feature Names:\")\n",
    "print(poly_3.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model with transformed Features (`degree = 3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Model Performance:\n",
      "Training Set:\n",
      "RMSE: 2.940512343419126\n",
      "R2: 0.9870443297925774\n",
      "\n",
      "Testing Set:\n",
      "RMSE: 3.0056638608303694\n",
      "R2: 0.9865149052434146\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear regression model on degree-3 polynomial features\n",
    "poly_3_model = LinearRegression()\n",
    "poly_3_model.fit(X_train_poly_3, y_train)\n",
    "\n",
    "# Predict on train and test splits\n",
    "y_pred_poly_3 = poly_3_model.predict(X_test_poly_3)\n",
    "y_pred_train_poly_3 = poly_3_model.predict(X_train_poly_3)\n",
    "\n",
    "# Evaluate on test and training sets\n",
    "rmse_poly_3 = root_mean_squared_error(y_test, y_pred_poly_3)\n",
    "r2_poly_3 = r2_score(y_test, y_pred_poly_3)\n",
    "\n",
    "rmse_poly_3_train = root_mean_squared_error(y_train, y_pred_train_poly_3)\n",
    "r2_poly_3_train = r2_score(y_train, y_pred_train_poly_3)\n",
    "\n",
    "print()\n",
    "print(\"Polynomial Model Performance:\")\n",
    "print(\"Training Set:\")\n",
    "print(\"RMSE:\", rmse_poly_3_train)\n",
    "print(\"R2:\", r2_poly_3_train)\n",
    "print()\n",
    "print(\"Testing Set:\")\n",
    "print(\"RMSE:\", rmse_poly_3)\n",
    "print(\"R2:\", r2_poly_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### `degree = 4`\n"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Model Performance:\n",
      "Training Set:\n",
      "RMSE: 2.9383287792953574\n",
      "R2: 0.98706356387817\n",
      "\n",
      "Testing Set:\n",
      "RMSE: 2.9985680032522617\n",
      "R2: 0.9865785020821749\n"
     ]
    }
   ],
   "source": "# use polynominal degree of 4 to see if it improves the model\npoly_4 = PolynomialFeatures(degree=4, include_bias=False)\n\n# Transform the training and testing features\nX_train_poly_4 = poly_4.fit_transform(X_train)\nX_test_poly_4 = poly_4.transform(X_test)\n\n# Create a linear regression model for the polynomial features\npoly_4_model = LinearRegression()\n\n# Train the model on the transformed features\npoly_4_model.fit(X_train_poly_4, y_train)\n\n# Make predictions on the test set\ny_pred_poly_4 = poly_4_model.predict(X_test_poly_4)\n\n# Make predictions on the training set\ny_pred_train_poly_4 = poly_4_model.predict(X_train_poly_4)\n\n# Evaluate the polynomial model\nrmse_poly_4 = root_mean_squared_error(y_test, y_pred_poly_4)\nr2_poly_4 = r2_score(y_test, y_pred_poly_4)\n\n# Evaluate the polynomial model on the training set\nrmse_poly_4_train = root_mean_squared_error(y_train, y_pred_train_poly_4)\nr2_poly_4_train = r2_score(y_train, y_pred_train_poly_4)\n\nprint()\nprint(\"Polynomial Model Performance:\")\nprint(\"Training Set:\")\nprint(\"RMSE:\", rmse_poly_4_train)\nprint(\"R2:\", r2_poly_4_train)\nprint()\nprint(\"Testing Set:\")\nprint(\"RMSE:\", rmse_poly_4)\nprint(\"R2:\", r2_poly_4)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Features: 14\n",
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2' 'x0^3' 'x0^2 x1' 'x0 x1^2' 'x1^3' 'x0^4'\n",
      " 'x0^3 x1' 'x0^2 x1^2' 'x0 x1^3' 'x1^4']\n"
     ]
    }
   ],
   "source": [
    "# get the feature names for the polynomial degree 4 model\n",
    "print(\"\\nNumber of Features:\", len(poly_4.get_feature_names_out()))\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_4.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Training MSE</th>\n",
       "      <th>Testing MSE</th>\n",
       "      <th>Training R2</th>\n",
       "      <th>Testing R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>2</td>\n",
       "      <td>14.793577</td>\n",
       "      <td>14.766592</td>\n",
       "      <td>0.672086</td>\n",
       "      <td>0.674513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Degree 2</td>\n",
       "      <td>5</td>\n",
       "      <td>9.762878</td>\n",
       "      <td>9.486906</td>\n",
       "      <td>0.857186</td>\n",
       "      <td>0.865655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Degree 3</td>\n",
       "      <td>9</td>\n",
       "      <td>2.940512</td>\n",
       "      <td>3.005664</td>\n",
       "      <td>0.987044</td>\n",
       "      <td>0.986515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial Degree 4</td>\n",
       "      <td>14</td>\n",
       "      <td>2.938329</td>\n",
       "      <td>2.998568</td>\n",
       "      <td>0.987064</td>\n",
       "      <td>0.986579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Features  Training MSE  Testing MSE  Training R2  \\\n",
       "0             Baseline         2     14.793577    14.766592     0.672086   \n",
       "1  Polynomial Degree 2         5      9.762878     9.486906     0.857186   \n",
       "2  Polynomial Degree 3         9      2.940512     3.005664     0.987044   \n",
       "3  Polynomial Degree 4        14      2.938329     2.998568     0.987064   \n",
       "\n",
       "   Testing R2  \n",
       "0    0.674513  \n",
       "1    0.865655  \n",
       "2    0.986515  \n",
       "3    0.986579  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "# Summarize model performance side by side\nmodels = ['Baseline', 'Polynomial Degree 2', 'Polynomial Degree 3', 'Polynomial Degree 4']\nfeatures = [\n    X.shape[1],\n    len(poly_2.get_feature_names_out()),\n    len(poly_3.get_feature_names_out()),\n    len(poly_4.get_feature_names_out()),\n]\ntraining_rmse = [rmse_train_baseline, rmse_train_poly_2, rmse_poly_3_train, rmse_poly_4_train]\ntesting_rmse = [rmse_baseline, rmse_poly_2, rmse_poly_3, rmse_poly_4]\ntraining_r2 = [r2_train_baseline, r2_train_poly_2, r2_poly_3_train, r2_poly_4_train]\ntesting_r2 = [r2_baseline, r2_poly_2, r2_poly_3, r2_poly_4]\n\nmodel_comparison = pd.DataFrame(\n    {\n        'Model': models,\n        'Features': features,\n        'Training RMSE': training_rmse,\n        'Testing RMSE': testing_rmse,\n        'Training R2': training_r2,\n        'Testing R2': testing_r2,\n    }\n)\n\nmodel_comparison\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when increase degree to 4, we can see the performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key takeaway:\n",
    "\n",
    "In `scikit-learn`, the built-in `PolynomialFeatures` transformer is somewhat \u201call or nothing\u201d: by default, it generates **all** polynomial terms (including interactions) up to a certain degree. You can toggle:\n",
    "\n",
    "* `interaction_only=True` to generate only cross-terms\n",
    "* `include_bias=False` to exclude the constant (bias) term,\n",
    "* `degree` to control how high the polynomial powers go.\n",
    "\n",
    "However, if you want **fine-grained control** over exactly which terms get generated (for example, only certain interaction terms, or only a subset of polynomial terms), you will need to create those features manually or write a custom transformer (skipped for beginner level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `interaction_only` for Cross Terms Only\n",
    "\n",
    "If your goal is only to capture interaction terms (i.e., $ x_1 \\times x_2 $, but no squares, cubes, etc.), you can set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0 x1']\n"
     ]
    }
   ],
   "source": [
    "poly_int = PolynomialFeatures(degree=6, \n",
    "                             interaction_only=True, \n",
    "                             include_bias=False)\n",
    "\n",
    "X_transformed = poly_int.fit_transform(X)\n",
    "\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_int.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to be very selective\u2014say, just add $x_1^2$ and $ x_1 \\times x_2 $ but not  $x_2^2$ \u2014the simplest approach is to create columns by hand. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x1', 'x2', 'x1^2', 'x1*x2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -1.25459881,  -1.0636448 ,   1.57401818,   1.3344475 ],\n",
       "       [  4.50714306,  -0.26564341,  20.3143386 ,  -1.19729284],\n",
       "       [  2.31993942,   3.54547393,   5.3821189 ,   8.22528473],\n",
       "       [  0.98658484,  -1.59995614,   0.97334965,  -1.57849247],\n",
       "       [ -3.4398136 ,   3.69649685,  11.83231757, -12.71526011]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "N = 5000\n",
    "\n",
    "# Generate features from uniform distributions\n",
    "x1 = np.random.uniform(-5, 5, N)\n",
    "x2 = np.random.uniform(-5, 5, N)\n",
    "\n",
    "# Define a nonlinear relationship with Gaussian noise\n",
    "y = 1.5 * (x1 ** 2) + 0.5 * (x2 ** 3) + np.random.normal(loc=3, scale=3, size=N)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df.to_csv('nonlinear_dataset.csv', index=False)\n",
    "\n",
    "df.head(10)  # Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `PolynomialFeatures` (or any other scikit-learn transformer), the fitting step is always done on the training data\u2014not on the test data. This is a fundamental principle of machine learning pipelines: we do not use the test set for any part of model training (including feature encoding, feature generation, scaling, etc.). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}