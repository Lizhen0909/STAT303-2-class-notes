<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Regularization – Data Science II with python (Class notes)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Feature Selection.html" rel="next">
<link href="./cross_validation.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Regularization in Python.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regularization</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="https://statistics.northwestern.edu/" class="sidebar-logo-link">
      <img src="./NU_Stat_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science II with python (Class notes)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec1_SimpleLinearRegression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple Linear Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec2_MultipleLinearRegression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec3_VariableTransformations_and_Interactions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Extending Linear Regression (statsmodels)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./polynominal_features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Extending Linear Regression (PolynomialFeatures in Sklearn)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./potential_issue_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Beyond Fit (implementation)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Lec5_Potential_issues.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Beyond Fit (statistical theory)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Logistic Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Logistic regression: Introduction and Metrics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Logistic Regression - Decision Boundary and Feature Engineering (Nonlinear Features).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Logistic regression: Others</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cross_validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Cross-Validation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Regularization in Python.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Feature Selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Feature Selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment_1_wi25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Assignment 1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment 2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Assignment 2</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment 3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Assignment 3</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Assignment 4</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Assignment5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Assignment 5</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Datasets, assignment and project files</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#why-do-we-need-regularization" id="toc-why-do-we-need-regularization" class="nav-link active" data-scroll-target="#why-do-we-need-regularization"><span class="header-section-number">10.1</span> Why do we need regularization?</a>
  <ul>
  <li><a href="#the-challenge-of-overfitting-and-underfitting" id="toc-the-challenge-of-overfitting-and-underfitting" class="nav-link" data-scroll-target="#the-challenge-of-overfitting-and-underfitting"><span class="header-section-number">10.1.1</span> The Challenge of Overfitting and Underfitting</a></li>
  <li><a href="#understanding-the-bias-variance-tradeoff" id="toc-understanding-the-bias-variance-tradeoff" class="nav-link" data-scroll-target="#understanding-the-bias-variance-tradeoff"><span class="header-section-number">10.1.2</span> Understanding the Bias-Variance Tradeoff</a></li>
  <li><a href="#visualizing-overfitting-vs.-underfitting" id="toc-visualizing-overfitting-vs.-underfitting" class="nav-link" data-scroll-target="#visualizing-overfitting-vs.-underfitting"><span class="header-section-number">10.1.3</span> Visualizing Overfitting vs.&nbsp;Underfitting</a></li>
  </ul></li>
  <li><a href="#simulating-data-for-an-overfitting-linear-model" id="toc-simulating-data-for-an-overfitting-linear-model" class="nav-link" data-scroll-target="#simulating-data-for-an-overfitting-linear-model"><span class="header-section-number">10.2</span> Simulating Data for an Overfitting Linear Model</a>
  <ul>
  <li><a href="#generating-the-data" id="toc-generating-the-data" class="nav-link" data-scroll-target="#generating-the-data"><span class="header-section-number">10.2.1</span> Generating the data</a></li>
  <li><a href="#splitting-the-data" id="toc-splitting-the-data" class="nav-link" data-scroll-target="#splitting-the-data"><span class="header-section-number">10.2.2</span> Splitting the Data</a></li>
  <li><a href="#splitting-the-target-and-features" id="toc-splitting-the-target-and-features" class="nav-link" data-scroll-target="#splitting-the-target-and-features"><span class="header-section-number">10.2.3</span> Splitting the target and features</a></li>
  <li><a href="#building-models" id="toc-building-models" class="nav-link" data-scroll-target="#building-models"><span class="header-section-number">10.2.4</span> Building Models</a>
  <ul class="collapse">
  <li><a href="#building-a-linear-model-with-only-1-predictor-x" id="toc-building-a-linear-model-with-only-1-predictor-x" class="nav-link" data-scroll-target="#building-a-linear-model-with-only-1-predictor-x"><span class="header-section-number">10.2.4.1</span> Building a linear model with only 1 predictor <code>x</code></a></li>
  <li><a href="#building-a-linear-regression-model-with-three-features-x-x_2-x_3" id="toc-building-a-linear-regression-model-with-three-features-x-x_2-x_3" class="nav-link" data-scroll-target="#building-a-linear-regression-model-with-three-features-x-x_2-x_3"><span class="header-section-number">10.2.4.2</span> Building a linear regression model with three features <code>x, x_2, x_3</code></a></li>
  </ul></li>
  <li><a href="#overfitting-indicated-by-training-and-test-mrss-trends" id="toc-overfitting-indicated-by-training-and-test-mrss-trends" class="nav-link" data-scroll-target="#overfitting-indicated-by-training-and-test-mrss-trends"><span class="header-section-number">10.2.5</span> Overfitting Indicated by Training and Test MRSS Trends</a></li>
  </ul></li>
  <li><a href="#regularization-combating-overfitting" id="toc-regularization-combating-overfitting" class="nav-link" data-scroll-target="#regularization-combating-overfitting"><span class="header-section-number">10.3</span> Regularization: Combating Overfitting</a>
  <ul>
  <li><a href="#regularized-loss-function" id="toc-regularized-loss-function" class="nav-link" data-scroll-target="#regularized-loss-function"><span class="header-section-number">10.3.1</span> Regularized Loss Function</a></li>
  <li><a href="#regularization-does-not-penalize-the-intercept" id="toc-regularization-does-not-penalize-the-intercept" class="nav-link" data-scroll-target="#regularization-does-not-penalize-the-intercept"><span class="header-section-number">10.3.2</span> Regularization Does Not Penalize the Intercept</a></li>
  <li><a href="#types-of-regularization" id="toc-types-of-regularization" class="nav-link" data-scroll-target="#types-of-regularization"><span class="header-section-number">10.3.3</span> Types of Regularization</a></li>
  <li><a href="#why-is-feature-scaling-required-in-regularization" id="toc-why-is-feature-scaling-required-in-regularization" class="nav-link" data-scroll-target="#why-is-feature-scaling-required-in-regularization"><span class="header-section-number">10.3.4</span> Why Is Feature Scaling Required in Regularization?</a>
  <ul class="collapse">
  <li><a href="#the-effect-of-feature-magnitudes-on-regularization" id="toc-the-effect-of-feature-magnitudes-on-regularization" class="nav-link" data-scroll-target="#the-effect-of-feature-magnitudes-on-regularization"><span class="header-section-number">10.3.4.1</span> The Effect of Feature Magnitudes on Regularization</a></li>
  <li><a href="#example-the-need-for-feature-scaling" id="toc-example-the-need-for-feature-scaling" class="nav-link" data-scroll-target="#example-the-need-for-feature-scaling"><span class="header-section-number">10.3.4.2</span> Example: The Need for Feature Scaling</a></li>
  <li><a href="#how-to-scale-features-for-regularization" id="toc-how-to-scale-features-for-regularization" class="nav-link" data-scroll-target="#how-to-scale-features-for-regularization"><span class="header-section-number">10.3.4.3</span> How to Scale Features for Regularization</a></li>
  </ul></li>
  <li><a href="#ridge-regression-l2-regularization" id="toc-ridge-regression-l2-regularization" class="nav-link" data-scroll-target="#ridge-regression-l2-regularization"><span class="header-section-number">10.3.5</span> Ridge Regression: L2 Regularization</a>
  <ul class="collapse">
  <li><a href="#ridge-regression-loss-function" id="toc-ridge-regression-loss-function" class="nav-link" data-scroll-target="#ridge-regression-loss-function"><span class="header-section-number">10.3.5.1</span> Ridge Regression Loss Function</a></li>
  </ul></li>
  <li><a href="#lasso-regression-l1-regularization" id="toc-lasso-regression-l1-regularization" class="nav-link" data-scroll-target="#lasso-regression-l1-regularization"><span class="header-section-number">10.3.6</span> Lasso Regression: L1 Regularization</a>
  <ul class="collapse">
  <li><a href="#lasso-regression-loss-function" id="toc-lasso-regression-loss-function" class="nav-link" data-scroll-target="#lasso-regression-loss-function"><span class="header-section-number">10.3.6.1</span> Lasso Regression Loss Function</a></li>
  </ul></li>
  <li><a href="#elastic-net-regression-combining-l1-and-l2-regularization" id="toc-elastic-net-regression-combining-l1-and-l2-regularization" class="nav-link" data-scroll-target="#elastic-net-regression-combining-l1-and-l2-regularization"><span class="header-section-number">10.3.7</span> Elastic Net Regression: Combining L1 and L2 Regularization</a>
  <ul class="collapse">
  <li><a href="#mathematical-formulation" id="toc-mathematical-formulation" class="nav-link" data-scroll-target="#mathematical-formulation"><span class="header-section-number">10.3.7.1</span> Mathematical Formulation*</a></li>
  <li><a href="#elastic-net-special-cases" id="toc-elastic-net-special-cases" class="nav-link" data-scroll-target="#elastic-net-special-cases"><span class="header-section-number">10.3.7.2</span> Elastic Net Special Cases</a></li>
  </ul></li>
  <li><a href="#ridgecv-lassocv-and-elasticnetcv-in-scikit-learn" id="toc-ridgecv-lassocv-and-elasticnetcv-in-scikit-learn" class="nav-link" data-scroll-target="#ridgecv-lassocv-and-elasticnetcv-in-scikit-learn"><span class="header-section-number">10.3.8</span> <code>RidgeCV</code>, <code>LassoCV</code>, and <code>ElasticNetCV</code> in Scikit-Learn</a>
  <ul class="collapse">
  <li><a href="#overview-of-ridgecv-lassocv-and-elasticnetcv" id="toc-overview-of-ridgecv-lassocv-and-elasticnetcv" class="nav-link" data-scroll-target="#overview-of-ridgecv-lassocv-and-elasticnetcv"><span class="header-section-number">10.3.8.1</span> Overview of RidgeCV, LassoCV, and ElasticNetCV**</a></li>
  <li><a href="#how-to-use-ridgecv-lassocv-andelasticnetcv" id="toc-how-to-use-ridgecv-lassocv-andelasticnetcv" class="nav-link" data-scroll-target="#how-to-use-ridgecv-lassocv-andelasticnetcv"><span class="header-section-number">10.3.8.2</span> How to Use <code>RidgeCV</code>, <code>LassoCV</code>, and<code>ElasticNetCV</code></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference"><span class="header-section-number">10.4</span> Reference</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regularization</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="31087b76" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display" data-execution_count="1">
<img src="./Datasets/Regularization.webp" width="700" height="300">
</div>
</div>
<div id="d67078da" class="cell" data-scrolled="true" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'ggplot'</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pylab <span class="im">import</span> rcParams</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> <span class="dv">5</span>, <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="why-do-we-need-regularization" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="why-do-we-need-regularization"><span class="header-section-number">10.1</span> Why do we need regularization?</h2>
<section id="the-challenge-of-overfitting-and-underfitting" class="level3" data-number="10.1.1">
<h3 data-number="10.1.1" class="anchored" data-anchor-id="the-challenge-of-overfitting-and-underfitting"><span class="header-section-number">10.1.1</span> The Challenge of Overfitting and Underfitting</h3>
<p>When building machine learning models, we aim to find patterns in data that generalize well to unseen samples. However, models can suffer from two key issues:</p>
<ul>
<li><strong>Underfitting</strong>: The model is too simple to capture the underlying pattern in the data.</li>
<li><strong>Overfitting</strong>: The model is too complex and captures noise rather than generalizable patterns.</li>
</ul>
<p><strong>Regularization</strong> is a technique used to address overfitting by penalizing overly complex models.</p>
</section>
<section id="understanding-the-bias-variance-tradeoff" class="level3" data-number="10.1.2">
<h3 data-number="10.1.2" class="anchored" data-anchor-id="understanding-the-bias-variance-tradeoff"><span class="header-section-number">10.1.2</span> Understanding the Bias-Variance Tradeoff</h3>
<p>A well-performing model balances two competing sources of error:</p>
<ul>
<li><strong>Bias</strong>: Error due to overly simplistic assumptions (e.g., underfitting).</li>
<li><strong>Variance</strong>: Error due to excessive sensitivity to training data (e.g., overfitting).</li>
</ul>
<p>A <strong>high-bias</strong> model (e.g., a simple linear regression) may not capture the underlying trend, while a <strong>high-variance</strong> model (e.g., a deep neural network with many parameters) may memorize noise instead of learning meaningful patterns.</p>
<p>Regularization helps <strong>reduce variance</strong> while maintaining an appropriate level of model complexity.</p>
</section>
<section id="visualizing-overfitting-vs.-underfitting" class="level3" data-number="10.1.3">
<h3 data-number="10.1.3" class="anchored" data-anchor-id="visualizing-overfitting-vs.-underfitting"><span class="header-section-number">10.1.3</span> Visualizing Overfitting vs.&nbsp;Underfitting</h3>
<p>To better understand this concept, consider three different models:</p>
<ol type="1">
<li><strong>Underfitting (High Bias)</strong>: The model is too simple and fails to capture important trends.</li>
<li><strong>Good Fit (Balanced Bias &amp; Variance)</strong>: The model generalizes well to unseen data.</li>
<li><strong>Overfitting (High Variance)</strong>: The model is too complex and captures noise, leading to poor generalization.</li>
</ol>
<p><span class="math display">\[
\text{Total Error} = \text{Bias}^2 + \text{Variance} + \text{Irreducible Error}
\]</span></p>
<p>Regularization helps control <strong>variance</strong> by penalizing large coefficients, leading to a model that generalizes better.</p>
</section>
</section>
<section id="simulating-data-for-an-overfitting-linear-model" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="simulating-data-for-an-overfitting-linear-model"><span class="header-section-number">10.2</span> Simulating Data for an Overfitting Linear Model</h2>
<section id="generating-the-data" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="generating-the-data"><span class="header-section-number">10.2.1</span> Generating the data</h3>
<div id="543995e5" class="cell" data-scrolled="true" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Define input array with angles from 60deg to 300deg converted to radians</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([i<span class="op">*</span>np.pi<span class="op">/</span><span class="dv">180</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">360</span>)])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)  <span class="co">#Setting seed for reproducibility</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.sin(x) <span class="op">+</span> np.random.normal(<span class="dv">0</span>,<span class="fl">0.15</span>,<span class="bu">len</span>(x))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame(np.column_stack([x,y]),columns<span class="op">=</span>[<span class="st">'x'</span>,<span class="st">'y'</span>])</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">'x'</span>],data[<span class="st">'y'</span>],<span class="st">'.'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="8876521a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check how the data looks like</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.000000</td>
<td>0.199738</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.017453</td>
<td>0.124744</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.034907</td>
<td>-0.196911</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.052360</td>
<td>0.051078</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.069813</td>
<td>0.162957</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Polynomial features allow linear regression to model non-linear relationships. Higher-degree terms capture more complex patterns in the data. Let’s manually expands features, similar to <code>PolynomialFeatures</code> in <code>sklearn.preprocessing</code>. Using polynomial regression, we can evaluate different polynomial degrees and analyze the balance between underfitting and overfitting.</p>
<div id="2fc152d3" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>,<span class="dv">16</span>):  <span class="co">#power of 1 is already there</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    colname <span class="op">=</span> <span class="st">'x_</span><span class="sc">%d</span><span class="st">'</span><span class="op">%</span>i      <span class="co">#new var will be x_power</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    data[colname] <span class="op">=</span> data[<span class="st">'x'</span>]<span class="op">**</span>i</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">x_2</th>
<th data-quarto-table-cell-role="th">x_3</th>
<th data-quarto-table-cell-role="th">x_4</th>
<th data-quarto-table-cell-role="th">x_5</th>
<th data-quarto-table-cell-role="th">x_6</th>
<th data-quarto-table-cell-role="th">x_7</th>
<th data-quarto-table-cell-role="th">x_8</th>
<th data-quarto-table-cell-role="th">x_9</th>
<th data-quarto-table-cell-role="th">x_10</th>
<th data-quarto-table-cell-role="th">x_11</th>
<th data-quarto-table-cell-role="th">x_12</th>
<th data-quarto-table-cell-role="th">x_13</th>
<th data-quarto-table-cell-role="th">x_14</th>
<th data-quarto-table-cell-role="th">x_15</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.000000</td>
<td>0.199738</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.017453</td>
<td>0.124744</td>
<td>0.000305</td>
<td>0.000005</td>
<td>9.279177e-08</td>
<td>1.619522e-09</td>
<td>2.826599e-11</td>
<td>4.933346e-13</td>
<td>8.610313e-15</td>
<td>1.502783e-16</td>
<td>2.622851e-18</td>
<td>4.577739e-20</td>
<td>7.989662e-22</td>
<td>1.394459e-23</td>
<td>2.433790e-25</td>
<td>4.247765e-27</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.034907</td>
<td>-0.196911</td>
<td>0.001218</td>
<td>0.000043</td>
<td>1.484668e-06</td>
<td>5.182470e-08</td>
<td>1.809023e-09</td>
<td>6.314683e-11</td>
<td>2.204240e-12</td>
<td>7.694250e-14</td>
<td>2.685800e-15</td>
<td>9.375210e-17</td>
<td>3.272566e-18</td>
<td>1.142341e-19</td>
<td>3.987522e-21</td>
<td>1.391908e-22</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.052360</td>
<td>0.051078</td>
<td>0.002742</td>
<td>0.000144</td>
<td>7.516134e-06</td>
<td>3.935438e-07</td>
<td>2.060591e-08</td>
<td>1.078923e-09</td>
<td>5.649226e-11</td>
<td>2.957928e-12</td>
<td>1.548767e-13</td>
<td>8.109328e-15</td>
<td>4.246034e-16</td>
<td>2.223218e-17</td>
<td>1.164074e-18</td>
<td>6.095079e-20</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.069813</td>
<td>0.162957</td>
<td>0.004874</td>
<td>0.000340</td>
<td>2.375469e-05</td>
<td>1.658390e-06</td>
<td>1.157775e-07</td>
<td>8.082794e-09</td>
<td>5.642855e-10</td>
<td>3.939456e-11</td>
<td>2.750259e-12</td>
<td>1.920043e-13</td>
<td>1.340443e-14</td>
<td>9.358057e-16</td>
<td>6.533156e-17</td>
<td>4.561003e-18</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>What This Code Does</p>
<ul>
<li><strong>Generates Higher-Degree Polynomial Features</strong>: Iterates over the range <strong>2 to 15</strong>, computing polynomial terms (<code>x², x³, ..., x¹⁵</code>).</li>
<li><strong>Dynamically Creates Column Names</strong>: New feature names are automatically generated in the format <strong><code>x_2, x_3, ..., x_15</code></strong>.</li>
<li><strong>Expands the Dataset</strong>: Each polynomial-transformed feature is stored</li>
</ul>
</section>
<section id="splitting-the-data" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="splitting-the-data"><span class="header-section-number">10.2.2</span> Splitting the Data</h3>
<p>Next, we will split the data into <strong>training and testing sets</strong>. As we’ve learned, models tend to <strong>overfit</strong> when trained on a small dataset.</p>
<p>To intentionally create an <strong>overfitting scenario</strong>, we will: - Use <strong>only 10% of the data for training</strong>. - Reserve <strong>90% of the data for testing</strong>.</p>
<p>This is <strong>not a typical train-test split</strong> but is deliberately done to <strong>demonstrate overfitting</strong>, where the model performs well on the training data but generalizes poorly to unseen data.</p>
<div id="973ba7da" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>train, test <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cf8a7712" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of observations in the training data:'</span>, <span class="bu">len</span>(train))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of observations in the test data:'</span>,<span class="bu">len</span>(test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of observations in the training data: 36
Number of observations in the test data: 324</code></pre>
</div>
</div>
</section>
<section id="splitting-the-target-and-features" class="level3" data-number="10.2.3">
<h3 data-number="10.2.3" class="anchored" data-anchor-id="splitting-the-target-and-features"><span class="header-section-number">10.2.3</span> Splitting the target and features</h3>
<div id="5609a194" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> train.drop(<span class="st">'y'</span>, axis<span class="op">=</span><span class="dv">1</span>).values</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> train.y.values</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> test.drop(<span class="st">'y'</span>, axis<span class="op">=</span><span class="dv">1</span>).values</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> test.y.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="building-models" class="level3" data-number="10.2.4">
<h3 data-number="10.2.4" class="anchored" data-anchor-id="building-models"><span class="header-section-number">10.2.4</span> Building Models</h3>
<section id="building-a-linear-model-with-only-1-predictor-x" class="level4" data-number="10.2.4.1">
<h4 data-number="10.2.4.1" class="anchored" data-anchor-id="building-a-linear-model-with-only-1-predictor-x"><span class="header-section-number">10.2.4.1</span> Building a linear model with only 1 predictor <code>x</code></h4>
<div id="ee82edee" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear regression with one feature</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>independent_variable_train <span class="op">=</span> X_train[:, <span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>linreg <span class="op">=</span> LinearRegression()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>linreg.fit(independent_variable_train, y_train)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> linreg.predict(independent_variable_train)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>rss_train <span class="op">=</span> <span class="bu">sum</span>((y_train_pred<span class="op">-</span>y_train)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>X_train.shape[<span class="dv">0</span>]</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>independent_variable_test <span class="op">=</span> X_test[:, <span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> linreg.predict(independent_variable_test)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>rss_test <span class="op">=</span> <span class="bu">sum</span>((y_test_pred<span class="op">-</span>y_test)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>X_test.shape[<span class="dv">0</span>]</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Error"</span>, rss_train)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Error"</span>, rss_test)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>plt.plot(X_train[:, <span class="dv">0</span>:<span class="dv">1</span>], y_train_pred)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>plt.plot(X_train[:, <span class="dv">0</span>:<span class="dv">1</span>], y_train, <span class="st">'.'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Error 0.22398220582126424
Testing Error 0.22151086120574928</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="building-a-linear-regression-model-with-three-features-x-x_2-x_3" class="level4" data-number="10.2.4.2">
<h4 data-number="10.2.4.2" class="anchored" data-anchor-id="building-a-linear-regression-model-with-three-features-x-x_2-x_3"><span class="header-section-number">10.2.4.2</span> Building a linear regression model with three features <code>x, x_2, x_3</code></h4>
<div id="5f5cf4a5" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>independent_variable_train <span class="op">=</span> X_train[:, <span class="dv">0</span>:<span class="dv">3</span>]</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>independent_variable_train[:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>array([[ 1.36135682,  1.85329238,  2.52299222],
       [ 2.30383461,  5.30765392, 12.22795682],
       [ 1.51843645,  2.30564925,  3.50098186]])</code></pre>
</div>
</div>
<div id="6a9f32bc" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sort_xy(x,y):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.argsort(x)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    x2,y2<span class="op">=</span> x[idx] ,y[idx] </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x2,y2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="269895d4" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear regression with 3 features</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>linreg <span class="op">=</span> LinearRegression()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>linreg.fit(independent_variable_train, y_train)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> linreg.predict(independent_variable_train)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>rss_train <span class="op">=</span> <span class="bu">sum</span>((y_train_pred<span class="op">-</span>y_train)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>X_train.shape[<span class="dv">0</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>independent_variable_test <span class="op">=</span> X_test[:, <span class="dv">0</span>:<span class="dv">3</span>]</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> linreg.predict(independent_variable_test)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>rss_test <span class="op">=</span> <span class="bu">sum</span>((y_test_pred<span class="op">-</span>y_test)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>X_test.shape[<span class="dv">0</span>]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Error"</span>, rss_train)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Error"</span>, rss_test)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="op">*</span>sort_xy(X_train[:, <span class="dv">0</span>], y_train_pred))</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>plt.plot(X_train[:, <span class="dv">0</span>], y_train, <span class="st">'.'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Error 0.02167114498970705
Testing Error 0.028159311299747036</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s define a helper function that dynamically builds and trains a linear regression model based on a specified number of features. It allows for flexibility in selecting features and automates the process for multiple models.</p>
<div id="64ac4a76" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function which will fit linear vregression model, plot the results, and return the coefficient</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> linear_regression(train_x, train_y, test_x, test_y, features, models_to_plot):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#fit the model</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    linreg <span class="op">=</span> LinearRegression()</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    linreg.fit(train_x, train_y)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    train_y_pred <span class="op">=</span> linreg.predict(train_x)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    test_y_pred <span class="op">=</span> linreg.predict(test_x)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#check if a plot is to be made for the entered features</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> features <span class="kw">in</span> models_to_plot:</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        plt.subplot(models_to_plot[features])</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># plt_tight_layout()</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="op">*</span>sort_xy(train_x[:, <span class="dv">0</span>], train_y_pred))</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        plt.plot(train_x[:, <span class="dv">0</span>], train_y, <span class="st">'.'</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Number of Predictors: </span><span class="sc">%d</span><span class="st">'</span><span class="op">%</span>features)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#return the result in pre-defined format</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    rss_train <span class="op">=</span> <span class="bu">sum</span>((train_y_pred <span class="op">-</span> train_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>train_x.shape[<span class="dv">0</span>]</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    ret <span class="op">=</span> [rss_train]</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    rss_test <span class="op">=</span> <span class="bu">sum</span>((test_y_pred <span class="op">-</span> test_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>test_x.shape[<span class="dv">0</span>]</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    ret.extend([rss_test])</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    ret.extend([linreg.intercept_])</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    ret.extend(linreg.coef_)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ret</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="149a7127" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#initialize a dataframe to store the results:</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> [<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>, <span class="st">'intercept'</span>] <span class="op">+</span> [<span class="st">'coef_VaR_</span><span class="sc">%d</span><span class="st">'</span><span class="op">%</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">16</span>)]</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>ind <span class="op">=</span> [<span class="st">'Number_of_variable_</span><span class="sc">%d</span><span class="st">'</span><span class="op">%</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">16</span>)]</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>coef_matrix_simple <span class="op">=</span> pd.DataFrame(index<span class="op">=</span>ind, columns<span class="op">=</span>col)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a484a1c3" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the number of features for which a plot is required:</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>models_to_plot <span class="op">=</span> {<span class="dv">1</span>:<span class="dv">231</span>, <span class="dv">3</span>:<span class="dv">232</span>, <span class="dv">6</span>:<span class="dv">233</span>, <span class="dv">9</span>:<span class="dv">234</span>, <span class="dv">12</span>:<span class="dv">235</span>, <span class="dv">15</span>:<span class="dv">236</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0b6c4a62" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through all powers and store the results in a matrix form</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">16</span>):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    train_x <span class="op">=</span> X_train[:, <span class="dv">0</span>:i]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    train_y <span class="op">=</span> y_train</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    test_x <span class="op">=</span> X_test[:, <span class="dv">0</span>:i]</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    test_y <span class="op">=</span> y_test</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    coef_matrix_simple.iloc[i<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>:i<span class="op">+</span><span class="dv">3</span>] <span class="op">=</span> linear_regression(train_x, train_y, test_x, test_y, features<span class="op">=</span>i, models_to_plot<span class="op">=</span>models_to_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key Takeaways:</strong></p>
<p>As we increase the number of features (higher-degree polynomial terms), we observe the following:<br>
- The model becomes <strong>more flexible</strong>, capturing intricate patterns in the training data.<br>
- The curve becomes <strong>increasingly wavy and complex</strong>, adapting too closely to the data points.<br>
- This results in <strong>overfitting</strong>, where the model performs well on the training set but fails to generalize to unseen data.</p>
<p>Overfitting occurs because the model learns <strong>noise</strong> instead of the true underlying pattern, leading to poor performance on new data.</p>
<p>To better understand this phenomenon, let’s:<br>
- <strong>Evaluate model performance</strong> on both the training and test sets.<br>
- <strong>Output the model coefficients</strong> to analyze how feature coefficients changes with increasing complexity.</p>
<div id="3e5cedb7" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the display format to be scientific for ease of analysis</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>pd.options.display.float_format <span class="op">=</span> <span class="st">'</span><span class="sc">{:,.2g}</span><span class="st">'</span>.<span class="bu">format</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>coef_matrix_simple</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mrss_train</th>
<th data-quarto-table-cell-role="th">mrss_test</th>
<th data-quarto-table-cell-role="th">intercept</th>
<th data-quarto-table-cell-role="th">coef_VaR_1</th>
<th data-quarto-table-cell-role="th">coef_VaR_2</th>
<th data-quarto-table-cell-role="th">coef_VaR_3</th>
<th data-quarto-table-cell-role="th">coef_VaR_4</th>
<th data-quarto-table-cell-role="th">coef_VaR_5</th>
<th data-quarto-table-cell-role="th">coef_VaR_6</th>
<th data-quarto-table-cell-role="th">coef_VaR_7</th>
<th data-quarto-table-cell-role="th">coef_VaR_8</th>
<th data-quarto-table-cell-role="th">coef_VaR_9</th>
<th data-quarto-table-cell-role="th">coef_VaR_10</th>
<th data-quarto-table-cell-role="th">coef_VaR_11</th>
<th data-quarto-table-cell-role="th">coef_VaR_12</th>
<th data-quarto-table-cell-role="th">coef_VaR_13</th>
<th data-quarto-table-cell-role="th">coef_VaR_14</th>
<th data-quarto-table-cell-role="th">coef_VaR_15</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_1</td>
<td>0.22</td>
<td>0.22</td>
<td>0.88</td>
<td>-0.29</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Number_of_variable_2</td>
<td>0.22</td>
<td>0.22</td>
<td>0.84</td>
<td>-0.25</td>
<td>-0.0057</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_3</td>
<td>0.022</td>
<td>0.028</td>
<td>-0.032</td>
<td>1.7</td>
<td>-0.83</td>
<td>0.089</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Number_of_variable_4</td>
<td>0.021</td>
<td>0.03</td>
<td>-0.09</td>
<td>2</td>
<td>-1</td>
<td>0.14</td>
<td>-0.0037</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_5</td>
<td>0.02</td>
<td>0.025</td>
<td>-0.019</td>
<td>1.5</td>
<td>-0.48</td>
<td>-0.092</td>
<td>0.037</td>
<td>-0.0026</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Number_of_variable_6</td>
<td>0.019</td>
<td>0.029</td>
<td>-0.13</td>
<td>2.4</td>
<td>-1.9</td>
<td>0.77</td>
<td>-0.21</td>
<td>0.031</td>
<td>-0.0017</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_7</td>
<td>0.017</td>
<td>0.034</td>
<td>-0.37</td>
<td>4.7</td>
<td>-6.5</td>
<td>4.7</td>
<td>-1.9</td>
<td>0.4</td>
<td>-0.044</td>
<td>0.0019</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Number_of_variable_8</td>
<td>0.017</td>
<td>0.035</td>
<td>-0.42</td>
<td>5.3</td>
<td>-8</td>
<td>6.4</td>
<td>-2.9</td>
<td>0.73</td>
<td>-0.1</td>
<td>0.0076</td>
<td>-0.00022</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_9</td>
<td>0.016</td>
<td>0.036</td>
<td>-0.57</td>
<td>7.1</td>
<td>-14</td>
<td>16</td>
<td>-9.9</td>
<td>3.8</td>
<td>-0.91</td>
<td>0.13</td>
<td>-0.011</td>
<td>0.00037</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Number_of_variable_10</td>
<td>0.016</td>
<td>0.036</td>
<td>-0.51</td>
<td>6.2</td>
<td>-11</td>
<td>9.7</td>
<td>-4.5</td>
<td>0.83</td>
<td>0.11</td>
<td>-0.087</td>
<td>0.018</td>
<td>-0.0017</td>
<td>6.6e-05</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_11</td>
<td>0.014</td>
<td>0.044</td>
<td>0.17</td>
<td>-4</td>
<td>36</td>
<td>-86</td>
<td>1e+02</td>
<td>-71</td>
<td>31</td>
<td>-8.8</td>
<td>1.6</td>
<td>-0.18</td>
<td>0.012</td>
<td>-0.00034</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Number_of_variable_12</td>
<td>0.013</td>
<td>0.049</td>
<td>0.54</td>
<td>-10</td>
<td>67</td>
<td>-1.6e+02</td>
<td>2e+02</td>
<td>-1.5e+02</td>
<td>74</td>
<td>-24</td>
<td>5.4</td>
<td>-0.8</td>
<td>0.076</td>
<td>-0.0041</td>
<td>0.0001</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_13</td>
<td>0.0086</td>
<td>0.065</td>
<td>-0.56</td>
<td>9.9</td>
<td>-56</td>
<td>2e+02</td>
<td>-3.9e+02</td>
<td>4.5e+02</td>
<td>-3.2e+02</td>
<td>1.6e+02</td>
<td>-51</td>
<td>11</td>
<td>-1.7</td>
<td>0.17</td>
<td>-0.0093</td>
<td>0.00023</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Number_of_variable_14</td>
<td>0.009</td>
<td>0.062</td>
<td>-0.075</td>
<td>0.62</td>
<td>7</td>
<td>-5.1</td>
<td>-12</td>
<td>11</td>
<td>9.4</td>
<td>-21</td>
<td>15</td>
<td>-6.2</td>
<td>1.6</td>
<td>-0.27</td>
<td>0.028</td>
<td>-0.0016</td>
<td>4.2e-05</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Number_of_variable_15</td>
<td>0.0097</td>
<td>0.061</td>
<td>-0.3</td>
<td>3.4</td>
<td>-0.93</td>
<td>-2</td>
<td>-0.61</td>
<td>1.2</td>
<td>1.2</td>
<td>-0.79</td>
<td>-1.2</td>
<td>1.6</td>
<td>-0.81</td>
<td>0.24</td>
<td>-0.043</td>
<td>0.0047</td>
<td>-0.00029</td>
<td>7.8e-06</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Let’s plot the training error versus the test error below and identify the overfitting</p>
<div id="f27d49b6" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>coef_matrix_simple[[<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>]].plot()</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.gca()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Features'</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'MRSS'</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.setp(ax.get_xticklabels(), rotation<span class="op">=</span><span class="dv">30</span>, horizontalalignment<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'train'</span>, <span class="st">'test'</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="overfitting-indicated-by-training-and-test-mrss-trends" class="level3" data-number="10.2.5">
<h3 data-number="10.2.5" class="anchored" data-anchor-id="overfitting-indicated-by-training-and-test-mrss-trends"><span class="header-section-number">10.2.5</span> Overfitting Indicated by Training and Test MRSS Trends</h3>
<p>As observed in the plot:<br>
- The <strong>Training Mean Residual Sum of Squares (MRSS)</strong> consistently decreases as the number of features increases.<br>
- However, after a certain point, the <strong>Test MRSS starts to rise</strong>, indicating that the model is no longer generalizing well to unseen data.</p>
<p>This trend suggests that while adding more features helps the model fit the <strong>training data</strong> better, it also causes the model to <strong>memorize noise</strong>, leading to poor performance on the test set.</p>
<p>This is a classic sign of <strong>overfitting</strong>, where the model captures excessive complexity in the data rather than the true underlying pattern.</p>
<p>Next, let’s mitigate the overfitting issue using regularization</p>
</section>
</section>
<section id="regularization-combating-overfitting" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="regularization-combating-overfitting"><span class="header-section-number">10.3</span> Regularization: Combating Overfitting</h2>
<p>Regularization is a technique that <strong>modifies the loss function</strong> by adding a penalty term to control model complexity.<br>
This helps <strong>prevent overfitting</strong> by discouraging large coefficients in the model.</p>
<section id="regularized-loss-function" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="regularized-loss-function"><span class="header-section-number">10.3.1</span> Regularized Loss Function</h3>
<p>The regularized loss function is given by:</p>
<p><span class="math inline">\(L_{reg}(\beta) = L(\beta) + \alpha R(\beta)\)</span></p>
<p>where: - <span class="math inline">\(L(\beta)\)</span> is the original loss function (e.g., Mean Squared Error in linear regression).<br>
- <span class="math inline">\(R(\beta)\)</span> is the <strong>regularization term</strong>, which penalizes large coefficients.<br>
- <span class="math inline">\(\alpha\)</span> is a <strong>hyperparameter</strong> that controls the strength of regularization.</p>
</section>
<section id="regularization-does-not-penalize-the-intercept" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="regularization-does-not-penalize-the-intercept"><span class="header-section-number">10.3.2</span> Regularization Does Not Penalize the Intercept</h3>
<ul>
<li>The <strong>intercept (bias term)</strong> captures the <strong>baseline mean</strong> of the target variable.<br>
</li>
<li>Penalizing the intercept would <strong>shift predictions</strong> incorrectly instead of controlling complexity.<br>
</li>
<li>Thus, regularization <strong>only applies to feature coefficients</strong>, not the intercept.</li>
</ul>
</section>
<section id="types-of-regularization" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3" class="anchored" data-anchor-id="types-of-regularization"><span class="header-section-number">10.3.3</span> Types of Regularization</h3>
<ol type="1">
<li><strong>L1 Regularization (Lasso Regression)</strong>: Encourages sparsity by driving some coefficients to zero.<br>
</li>
<li><strong>L2 Regularization (Ridge Regression)</strong>: Shrinks coefficients but keeps all of them nonzero.<br>
</li>
<li><strong>Elastic Net</strong>: A combination of both L1 and L2 regularization.</li>
</ol>
<p>By applying <strong>regularization</strong>, we obtain models that balance <strong>bias-variance tradeoff</strong>, leading to <strong>better generalization</strong>.</p>
</section>
<section id="why-is-feature-scaling-required-in-regularization" class="level3" data-number="10.3.4">
<h3 data-number="10.3.4" class="anchored" data-anchor-id="why-is-feature-scaling-required-in-regularization"><span class="header-section-number">10.3.4</span> Why Is Feature Scaling Required in Regularization?</h3>
<section id="the-effect-of-feature-magnitudes-on-regularization" class="level4" data-number="10.3.4.1">
<h4 data-number="10.3.4.1" class="anchored" data-anchor-id="the-effect-of-feature-magnitudes-on-regularization"><span class="header-section-number">10.3.4.1</span> The Effect of Feature Magnitudes on Regularization</h4>
<p>Regularization techniques such as <strong>Lasso (L1)</strong>, <strong>Ridge (L2)</strong>, and <strong>Elastic Net</strong> apply penalties to the model’s coefficients. However, when features have vastly different scales, <strong>regularization disproportionately affects certain features</strong>, leading to:</p>
<ul>
<li><strong>Uneven shrinkage</strong> of coefficients, causing instability in the model.</li>
<li><strong>Incorrect feature importance interpretation</strong>, as some features dominate due to their larger numerical scale.</li>
<li><strong>Suboptimal performance</strong>, since regularization penalizes large coefficients more, even if they belong to more informative features.</li>
</ul>
</section>
<section id="example-the-need-for-feature-scaling" class="level4" data-number="10.3.4.2">
<h4 data-number="10.3.4.2" class="anchored" data-anchor-id="example-the-need-for-feature-scaling"><span class="header-section-number">10.3.4.2</span> Example: The Need for Feature Scaling</h4>
<p>Imagine a dataset with two features:</p>
<ul>
<li><strong>Feature 1</strong>: Number of bedrooms (range: 1-5).<br>
</li>
<li><strong>Feature 2</strong>: House area in square feet (range: 500-5000).</li>
</ul>
<p>Since house area has much larger values, the model assigns smaller coefficients to compensate, making regularization unfairly <strong>biased toward smaller-scale features</strong>.</p>
</section>
<section id="how-to-scale-features-for-regularization" class="level4" data-number="10.3.4.3">
<h4 data-number="10.3.4.3" class="anchored" data-anchor-id="how-to-scale-features-for-regularization"><span class="header-section-number">10.3.4.3</span> How to Scale Features for Regularization</h4>
<p>To ensure fair treatment of all features, apply <strong>feature scaling</strong> before training a regularized model:</p>
<section id="standardization-recommended" class="level5" data-number="10.3.4.3.1">
<h5 data-number="10.3.4.3.1" class="anchored" data-anchor-id="standardization-recommended"><span class="header-section-number">10.3.4.3.1</span> Standardization (Recommended)</h5>
<p><span class="math display">\[
x_{\text{scaled}} = \frac{x - \mu}{\sigma}
\]</span> - Centers the data around <strong>zero</strong> with unit variance. - Used in <strong>Lasso, Ridge, and Elastic Net</strong>.</p>
</section>
<section id="min-max-scaling" class="level5" data-number="10.3.4.3.2">
<h5 data-number="10.3.4.3.2" class="anchored" data-anchor-id="min-max-scaling"><span class="header-section-number">10.3.4.3.2</span> Min-Max Scaling</h5>
<p><span class="math display">\[
x_{\text{scaled}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}
\]</span> - Scales features to a fixed <strong>[0, 1]</strong> range. - Common for <strong>neural networks</strong> but less effective for regularization.</p>
<p>Let’s use <code>StandardScaler</code> to scale the features</p>
<div id="7cc71193" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature scaling on X_train</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>X_train_std <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> data.drop(<span class="st">'y'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>X_train_std <span class="op">=</span> pd.DataFrame(X_train_std, columns <span class="op">=</span> columns)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>X_train_std.head()</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature scaling on X_test</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>X_test_std <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>X_test_std <span class="op">=</span> pd.DataFrame(X_test_std, columns <span class="op">=</span> columns)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>X_test_std.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">x_2</th>
<th data-quarto-table-cell-role="th">x_3</th>
<th data-quarto-table-cell-role="th">x_4</th>
<th data-quarto-table-cell-role="th">x_5</th>
<th data-quarto-table-cell-role="th">x_6</th>
<th data-quarto-table-cell-role="th">x_7</th>
<th data-quarto-table-cell-role="th">x_8</th>
<th data-quarto-table-cell-role="th">x_9</th>
<th data-quarto-table-cell-role="th">x_10</th>
<th data-quarto-table-cell-role="th">x_11</th>
<th data-quarto-table-cell-role="th">x_12</th>
<th data-quarto-table-cell-role="th">x_13</th>
<th data-quarto-table-cell-role="th">x_14</th>
<th data-quarto-table-cell-role="th">x_15</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-0.96</td>
<td>-1</td>
<td>-0.89</td>
<td>-0.78</td>
<td>-0.69</td>
<td>-0.62</td>
<td>-0.57</td>
<td>-0.52</td>
<td>-0.48</td>
<td>-0.45</td>
<td>-0.43</td>
<td>-0.4</td>
<td>-0.38</td>
<td>-0.37</td>
<td>-0.35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>-0.061</td>
<td>-0.34</td>
<td>-0.49</td>
<td>-0.55</td>
<td>-0.57</td>
<td>-0.56</td>
<td>-0.53</td>
<td>-0.5</td>
<td>-0.47</td>
<td>-0.45</td>
<td>-0.42</td>
<td>-0.4</td>
<td>-0.38</td>
<td>-0.37</td>
<td>-0.35</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-1.8</td>
<td>-1.2</td>
<td>-0.95</td>
<td>-0.8</td>
<td>-0.7</td>
<td>-0.62</td>
<td>-0.57</td>
<td>-0.52</td>
<td>-0.48</td>
<td>-0.45</td>
<td>-0.43</td>
<td>-0.4</td>
<td>-0.38</td>
<td>-0.37</td>
<td>-0.35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.21</td>
<td>-0.051</td>
<td>-0.24</td>
<td>-0.36</td>
<td>-0.43</td>
<td>-0.46</td>
<td>-0.47</td>
<td>-0.46</td>
<td>-0.45</td>
<td>-0.43</td>
<td>-0.41</td>
<td>-0.4</td>
<td>-0.38</td>
<td>-0.36</td>
<td>-0.35</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-1.7</td>
<td>-1.2</td>
<td>-0.95</td>
<td>-0.8</td>
<td>-0.7</td>
<td>-0.62</td>
<td>-0.57</td>
<td>-0.52</td>
<td>-0.48</td>
<td>-0.45</td>
<td>-0.43</td>
<td>-0.4</td>
<td>-0.38</td>
<td>-0.37</td>
<td>-0.35</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>In the next section, we will explore <strong>different types of regularization techniques</strong> and see how they help in preventing overfitting.</p>
</section>
</section>
</section>
<section id="ridge-regression-l2-regularization" class="level3" data-number="10.3.5">
<h3 data-number="10.3.5" class="anchored" data-anchor-id="ridge-regression-l2-regularization"><span class="header-section-number">10.3.5</span> Ridge Regression: L2 Regularization</h3>
<p>Ridge regression is a type of <strong>linear regression</strong> that incorporates <strong>L2 regularization</strong> to prevent overfitting by <strong>penalizing large coefficients</strong>.</p>
<section id="ridge-regression-loss-function" class="level4" data-number="10.3.5.1">
<h4 data-number="10.3.5.1" class="anchored" data-anchor-id="ridge-regression-loss-function"><span class="header-section-number">10.3.5.1</span> Ridge Regression Loss Function</h4>
<p>The regularized loss function for Ridge regression is given by:</p>
<p><span class="math display">\[
L_{\text{Ridge}}(\beta) = \frac{1}{n} \sum_{i=1}^{n} |y_i - \beta^\top x_i|^2 + \alpha \sum_{j=1}^{J} \beta_j^2
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(y_i \text{ is the true target value for observation } i.\)</span></li>
<li><span class="math inline">\(x_i \text{ is the feature vector for observation } i.\)</span></li>
<li><span class="math inline">\(\beta \text{ is the vector of model coefficients.}\)</span></li>
<li><span class="math inline">\(\alpha \text{ is the regularization parameter, which controls the penalty strength.}\)</span></li>
<li><span class="math inline">\(\sum_{j=1}^{J} \beta_j^2 \text{ is the L2 norm (sum of squared coefficients).}\)</span></li>
</ul>
<p><strong>Note that <span class="math inline">\(j\)</span> starts from 1, excluding the intercept from regularization.</strong></p>
<p>The penalty term in Ridge regression,</p>
<p><span class="math display">\[
\sum_{j=1}^{J} \beta_j^2 = ||\beta||_2^2
\]</span></p>
<p>is the <strong>squared L2 norm</strong> of the coefficient vector <span class="math inline">\(\beta\)</span>.<br>
Minimizing this norm ensures that the model coefficients remain <strong>small and stable</strong>, reducing sensitivity to variations in the data.</p>
<p>Let’s build a Ridge Regression model using scikit-learn, The <code>alpha</code> parameter controls the strength of the regularization:</p>
<div id="6a7d3b67" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># defining a function which will fit ridge regression model, plot the results, and return the coefficients</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ridge_regression(train_x, train_y, test_x, test_y, alpha, models_to_plot<span class="op">=</span>{}):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#fit the model</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    ridgereg <span class="op">=</span> Ridge(alpha<span class="op">=</span>alpha)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    ridgereg.fit(train_x, train_y)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    train_y_pred <span class="op">=</span> ridgereg.predict(train_x)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    test_y_pred <span class="op">=</span> ridgereg.predict(test_x)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#check if a plot is to be made for the entered alpha</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> alpha <span class="kw">in</span> models_to_plot:</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        plt.subplot(models_to_plot[alpha])</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># plt_tight_layout()</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="op">*</span>sort_xy(train_x.values[:, <span class="dv">0</span>], train_y_pred))</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>        plt.plot(train_x.values[:, <span class="dv">0</span>], train_y, <span class="st">'.'</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Plot for alpha: </span><span class="sc">%.3g</span><span class="st">'</span><span class="op">%</span>alpha)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#return the result in pre-defined format</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    mrss_train <span class="op">=</span> <span class="bu">sum</span>((train_y_pred <span class="op">-</span> train_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>train_x.shape[<span class="dv">0</span>]</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    ret <span class="op">=</span> [mrss_train]</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    mrss_test <span class="op">=</span> <span class="bu">sum</span>((test_y_pred <span class="op">-</span> test_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>test_x.shape[<span class="dv">0</span>]</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    ret.extend([mrss_test])</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    ret.extend([ridgereg.intercept_])</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>    ret.extend(ridgereg.coef_)</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ret</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s experiment with different values of alpha in Ridge Regression and observe how it affects the model’s coefficients and performance.</p>
<div id="d0b837d7" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#initialize a dataframe to store the coefficient:</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>alpha_ridge <span class="op">=</span> [<span class="fl">1e-15</span>, <span class="fl">1e-10</span>, <span class="fl">1e-8</span>, <span class="fl">1e-4</span>, <span class="fl">1e-3</span>,<span class="fl">1e-2</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>]</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> [<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>, <span class="st">'intercept'</span>] <span class="op">+</span> [<span class="st">'coef_VaR_</span><span class="sc">%d</span><span class="st">'</span><span class="op">%</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">16</span>)]</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>ind <span class="op">=</span> [<span class="st">'alpha_</span><span class="sc">%.2g</span><span class="st">'</span><span class="op">%</span>alpha_ridge[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>)]</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>coef_matrix_ridge <span class="op">=</span> pd.DataFrame(index<span class="op">=</span>ind, columns<span class="op">=</span>col)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="66145ab9" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the number of features for which a plot is required:</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>models_to_plot <span class="op">=</span> {<span class="fl">1e-15</span>:<span class="dv">231</span>, <span class="fl">1e-10</span>:<span class="dv">232</span>, <span class="fl">1e-4</span>:<span class="dv">233</span>, <span class="fl">1e-3</span>:<span class="dv">234</span>, <span class="fl">1e-2</span>:<span class="dv">235</span>, <span class="dv">5</span>:<span class="dv">236</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="dff2664d" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Iterate over the 10 alpha values:</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    coef_matrix_ridge.iloc[i,] <span class="op">=</span> ridge_regression(X_train_std, train_y, X_test_std, test_y, alpha_ridge[i], models_to_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As we can observe, when increasing alpha, the model becomes simpler, with coefficients shrinking more aggressively due to stronger regularization. This reduces the risk of overfitting but may lead to underfitting if alpha is set too high.</p>
<p>Next, let’s output the training error versus the test error and examine how the feature coefficients change with different alpha values.</p>
<div id="6436651a" class="cell" data-scrolled="true" data-execution_count="24">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set the display format to be scientific for ease of analysis</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>pd.options.display.float_format <span class="op">=</span> <span class="st">'</span><span class="sc">{:,.2g}</span><span class="st">'</span>.<span class="bu">format</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>coef_matrix_ridge</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mrss_train</th>
<th data-quarto-table-cell-role="th">mrss_test</th>
<th data-quarto-table-cell-role="th">intercept</th>
<th data-quarto-table-cell-role="th">coef_VaR_1</th>
<th data-quarto-table-cell-role="th">coef_VaR_2</th>
<th data-quarto-table-cell-role="th">coef_VaR_3</th>
<th data-quarto-table-cell-role="th">coef_VaR_4</th>
<th data-quarto-table-cell-role="th">coef_VaR_5</th>
<th data-quarto-table-cell-role="th">coef_VaR_6</th>
<th data-quarto-table-cell-role="th">coef_VaR_7</th>
<th data-quarto-table-cell-role="th">coef_VaR_8</th>
<th data-quarto-table-cell-role="th">coef_VaR_9</th>
<th data-quarto-table-cell-role="th">coef_VaR_10</th>
<th data-quarto-table-cell-role="th">coef_VaR_11</th>
<th data-quarto-table-cell-role="th">coef_VaR_12</th>
<th data-quarto-table-cell-role="th">coef_VaR_13</th>
<th data-quarto-table-cell-role="th">coef_VaR_14</th>
<th data-quarto-table-cell-role="th">coef_VaR_15</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1e-15</td>
<td>0.0092</td>
<td>0.059</td>
<td>-0.072</td>
<td>-2.8</td>
<td>1.9e+02</td>
<td>-1.3e+03</td>
<td>-6e+03</td>
<td>1.1e+05</td>
<td>-5.6e+05</td>
<td>1.5e+06</td>
<td>-2e+06</td>
<td>7.5e+05</td>
<td>1.4e+06</td>
<td>-1.4e+06</td>
<td>-7.5e+05</td>
<td>2e+06</td>
<td>-1.3e+06</td>
<td>2.8e+05</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_1e-10</td>
<td>0.016</td>
<td>0.036</td>
<td>-0.072</td>
<td>12</td>
<td>-1.3e+02</td>
<td>7.1e+02</td>
<td>-1.8e+03</td>
<td>1.8e+03</td>
<td>1.1e+03</td>
<td>-2.8e+03</td>
<td>-7.9e+02</td>
<td>2.4e+03</td>
<td>1.5e+03</td>
<td>-1.4e+03</td>
<td>-2.1e+03</td>
<td>3.5e+02</td>
<td>2.2e+03</td>
<td>-1e+03</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1e-08</td>
<td>0.017</td>
<td>0.034</td>
<td>-0.072</td>
<td>8.1</td>
<td>-70</td>
<td>2.8e+02</td>
<td>-5.6e+02</td>
<td>4.2e+02</td>
<td>1.7e+02</td>
<td>-2.6e+02</td>
<td>-1.8e+02</td>
<td>1e+02</td>
<td>1.8e+02</td>
<td>34</td>
<td>-1.1e+02</td>
<td>-79</td>
<td>64</td>
<td>3.8</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_0.0001</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.9</td>
<td>-8.2</td>
<td>4.5</td>
<td>-0.022</td>
<td>-1.3</td>
<td>0.31</td>
<td>1.8</td>
<td>2.1</td>
<td>1.1</td>
<td>-0.44</td>
<td>-1.8</td>
<td>-2.4</td>
<td>-1.9</td>
<td>-0.06</td>
<td>3.1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_0.001</td>
<td>0.019</td>
<td>0.023</td>
<td>-0.072</td>
<td>2.5</td>
<td>-5.6</td>
<td>-0.5</td>
<td>1.3</td>
<td>1.6</td>
<td>1.4</td>
<td>0.84</td>
<td>0.21</td>
<td>-0.39</td>
<td>-0.82</td>
<td>-1</td>
<td>-0.91</td>
<td>-0.48</td>
<td>0.28</td>
<td>1.3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_0.01</td>
<td>0.022</td>
<td>0.024</td>
<td>-0.072</td>
<td>1.9</td>
<td>-4</td>
<td>-1.3</td>
<td>0.73</td>
<td>1.5</td>
<td>1.3</td>
<td>0.82</td>
<td>0.23</td>
<td>-0.26</td>
<td>-0.58</td>
<td>-0.69</td>
<td>-0.6</td>
<td>-0.31</td>
<td>0.13</td>
<td>0.72</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1</td>
<td>0.089</td>
<td>0.093</td>
<td>-0.072</td>
<td>0.08</td>
<td>-0.61</td>
<td>-0.48</td>
<td>-0.22</td>
<td>-0.011</td>
<td>0.13</td>
<td>0.2</td>
<td>0.22</td>
<td>0.21</td>
<td>0.17</td>
<td>0.12</td>
<td>0.058</td>
<td>-0.0066</td>
<td>-0.072</td>
<td>-0.14</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_5</td>
<td>0.12</td>
<td>0.13</td>
<td>-0.072</td>
<td>-0.17</td>
<td>-0.3</td>
<td>-0.24</td>
<td>-0.14</td>
<td>-0.055</td>
<td>0.0059</td>
<td>0.046</td>
<td>0.069</td>
<td>0.08</td>
<td>0.081</td>
<td>0.077</td>
<td>0.069</td>
<td>0.057</td>
<td>0.045</td>
<td>0.031</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_10</td>
<td>0.14</td>
<td>0.14</td>
<td>-0.072</td>
<td>-0.19</td>
<td>-0.24</td>
<td>-0.18</td>
<td>-0.12</td>
<td>-0.058</td>
<td>-0.014</td>
<td>0.018</td>
<td>0.039</td>
<td>0.053</td>
<td>0.06</td>
<td>0.063</td>
<td>0.064</td>
<td>0.062</td>
<td>0.059</td>
<td>0.054</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_20</td>
<td>0.16</td>
<td>0.17</td>
<td>-0.072</td>
<td>-0.18</td>
<td>-0.19</td>
<td>-0.15</td>
<td>-0.097</td>
<td>-0.055</td>
<td>-0.022</td>
<td>0.0025</td>
<td>0.021</td>
<td>0.034</td>
<td>0.043</td>
<td>0.049</td>
<td>0.053</td>
<td>0.056</td>
<td>0.057</td>
<td>0.057</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>To better observe the pattern, let’s visualize how the coefficients change as we increase <span class="math inline">\(\alpha\)</span></p>
<div id="9376f1d6" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_ridge_reg_coeff(train_x):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> np.logspace(<span class="dv">3</span>,<span class="op">-</span><span class="dv">3</span>,<span class="dv">200</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    coefs <span class="op">=</span> []</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#X_train_std, train_y</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> a <span class="kw">in</span> alphas:        </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        ridge <span class="op">=</span> Ridge(alpha <span class="op">=</span> a)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        ridge.fit(train_x, train_y)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        coefs.append(ridge.coef_)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Visualizing the shrinkage in ridge regression coefficients with increasing values of the tuning parameter lambda</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'xlabel'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'ylabel'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(alphas, coefs)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="vs">r'$\alpha$'</span>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Feature coefficient'</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    plt.legend(train_x.columns )<span class="op">;</span>    </span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>plot_ridge_reg_coeff(X_train_std.iloc[:,:<span class="dv">5</span>])</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">"test.png"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-26-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As we can see, as <span class="math inline">\(\alpha\)</span> increases, the coefficients become smaller and approach zero. Now, let’s examine the number of zero coefficients.</p>
<div id="69db01d3" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>coef_matrix_ridge.<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">sum</span>(x.values<span class="op">==</span><span class="dv">0</span>),axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>alpha_1e-15     0
alpha_1e-10     0
alpha_1e-08     0
alpha_0.0001    0
alpha_0.001     0
alpha_0.01      0
alpha_1         0
alpha_5         0
alpha_10        0
alpha_20        0
dtype: int32</code></pre>
</div>
</div>
<p>Let’s plot how the test error and training error change as we increase <span class="math inline">\(\alpha\)</span></p>
<div id="448bd4c2" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>coef_matrix_ridge[[<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>]].plot()</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Features'</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'MRSS'</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'train'</span>, <span class="st">'test'</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As we can observe, as <span class="math inline">\(𝜆\)</span> increases beyond a certain value, both the training MRSS and test MRSS begin to rise, indicating that the model starts underfitting.</p>
</section>
</section>
<section id="lasso-regression-l1-regularization" class="level3" data-number="10.3.6">
<h3 data-number="10.3.6" class="anchored" data-anchor-id="lasso-regression-l1-regularization"><span class="header-section-number">10.3.6</span> Lasso Regression: L1 Regularization</h3>
<p>LASSO stands for <strong>Least Absolute Shrinkage and Selection Operator</strong>. There are two key aspects in this name:<br>
- <strong>“Absolute”</strong> refers to the use of the absolute values of the coefficients in the penalty term.<br>
- <strong>“Selection”</strong> highlights LASSO’s ability to shrink some coefficients to exactly zero, effectively performing <strong>feature selection</strong>.</p>
<p>Lasso regression performs <strong>L1 regularization</strong>, which helps prevent overfitting by penalizing large coefficients and enforcing sparsity in the model.</p>
<section id="lasso-regression-loss-function" class="level4" data-number="10.3.6.1">
<h4 data-number="10.3.6.1" class="anchored" data-anchor-id="lasso-regression-loss-function"><span class="header-section-number">10.3.6.1</span> Lasso Regression Loss Function</h4>
<p>In standard <strong>linear regression</strong>, the loss function is the <strong>Mean Squared Error (MSE)</strong>:</p>
<p><span class="math display">\[L_{\text{MSE}}(\beta) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \beta^\top x_i)^2\]</span></p>
<p>LASSO modifies this by adding an <strong>L1 regularization</strong> penalty, leading to the following <strong>regularized loss function</strong>:</p>
<p><span class="math display">\[L_{\text{Lasso}}(\beta) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \beta^\top x_i)^2 + \alpha  \sum_{j=1}^{J} |\beta_j|\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(y_i \text{ is the true target value for observation } i.\)</span></li>
<li><span class="math inline">\(x_i \text{ is the feature vector for observation } i.\)</span></li>
<li><span class="math inline">\(\beta \text{ is the vector of model coefficients.}\)</span></li>
<li><span class="math inline">\(\alpha \text{ is the regularization parameter, which controls the penalty strength.}\)</span></li>
<li><span class="math inline">\(\sum_{j=1}^{J} |\beta_j| \text{ is the } \mathbf{L_1} \text{ norm (sum of absolute values of coefficients).}\)</span></li>
</ul>
<p>The penalty term in Lasso regression,</p>
<p><span class="math display">\[
\sum_{j=1}^{J} |\beta_j| = ||\beta||_1
\]</span></p>
<p>is the <strong>L1 norm</strong> of the coefficient vector ( <span class="math inline">\(\beta\)</span> ).<br>
Minimizing this norm encourages <strong>sparsity</strong>, meaning some coefficients become exactly zero, leading to an automatically selected subset of features.</p>
<p>Next, let’s build a Lasso Regression model. Similar to Ridge regression, we will explore a range of values for the regularization parameter alpha.</p>
<div id="c94f3881" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>alpha_lasso <span class="op">=</span> [<span class="fl">1e-15</span>, <span class="fl">1e-10</span>, <span class="fl">1e-8</span>, <span class="fl">1e-5</span>,<span class="fl">1e-4</span>, <span class="fl">1e-3</span>,<span class="fl">1e-2</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bf8ea40a" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining a function which will fit lasso regression model, plot the results, and return the coefficient</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lasso_regression(train_x, train_y, test_x, test_y, alpha, models_to_plot<span class="op">=</span>{}):</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#fit the model</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> alpha <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>        lassoreg <span class="op">=</span> LinearRegression()    </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>        lassoreg <span class="op">=</span> Lasso(alpha<span class="op">=</span>alpha, max_iter<span class="op">=</span><span class="dv">200000000</span>, tol<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    lassoreg.fit(train_x, train_y)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    train_y_pred <span class="op">=</span> lassoreg.predict(train_x)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    test_y_pred <span class="op">=</span> lassoreg.predict(test_x)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#check if a plot is to be made for the entered alpha</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> alpha <span class="kw">in</span> models_to_plot:</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        plt.subplot(models_to_plot[alpha])</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># plt_tight_layout()</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="op">*</span>sort_xy(train_x.values[:, <span class="dv">0</span>], train_y_pred))</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        plt.plot(train_x.values[:, <span class="dv">0</span>:<span class="dv">1</span>], train_y, <span class="st">'.'</span>)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Plot for alpha: </span><span class="sc">%.3g</span><span class="st">'</span><span class="op">%</span>alpha)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#return the result in pre-defined format</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    mrss_train <span class="op">=</span> <span class="bu">sum</span>((train_y_pred <span class="op">-</span> train_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>train_x.shape[<span class="dv">0</span>]</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    ret <span class="op">=</span> [mrss_train]</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>    mrss_test <span class="op">=</span> <span class="bu">sum</span>((test_y_pred <span class="op">-</span> test_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>test_x.shape[<span class="dv">0</span>]</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    ret.extend([mrss_test])</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    ret.extend([lassoreg.intercept_])</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    ret.extend(lassoreg.coef_)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ret</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="92164f26" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#initialize a dataframe to store the coefficient:</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> [<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>, <span class="st">'intercept'</span>] <span class="op">+</span> [<span class="st">'coef_VaR_</span><span class="sc">%d</span><span class="st">'</span><span class="op">%</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">16</span>)]</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>ind <span class="op">=</span> [<span class="st">'alpha_</span><span class="sc">%.2g</span><span class="st">'</span><span class="op">%</span>alpha_lasso[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>)]</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>coef_matrix_lasso <span class="op">=</span> pd.DataFrame(index<span class="op">=</span>ind, columns<span class="op">=</span>col)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="591bbc29" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the number of features for which a plot is required:</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>models_to_plot <span class="op">=</span> {<span class="fl">1e-10</span>:<span class="dv">231</span>, <span class="fl">1e-5</span>:<span class="dv">232</span>,<span class="fl">1e-4</span>:<span class="dv">233</span>, <span class="fl">1e-3</span>:<span class="dv">234</span>, <span class="fl">1e-2</span>:<span class="dv">235</span>, <span class="fl">0.1</span>:<span class="dv">236</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="85361c39" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>models_to_plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>{1e-10: 231, 1e-05: 232, 0.0001: 233, 0.001: 234, 0.01: 235, 0.1: 236}</code></pre>
</div>
</div>
<div id="6d9ae207" class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Iterate over the 10 alpha values:</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    coef_matrix_lasso.iloc[i,] <span class="op">=</span> lasso_regression(X_train_std, train_y, X_test_std, test_y, alpha_lasso[i], models_to_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="75f59df9" class="cell" data-scrolled="true" data-execution_count="52">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set the display format to be scientific for ease of analysis</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>pd.options.display.float_format <span class="op">=</span> <span class="st">'</span><span class="sc">{:,.2g}</span><span class="st">'</span>.<span class="bu">format</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>coef_matrix_lasso</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mrss_train</th>
<th data-quarto-table-cell-role="th">mrss_test</th>
<th data-quarto-table-cell-role="th">intercept</th>
<th data-quarto-table-cell-role="th">coef_VaR_1</th>
<th data-quarto-table-cell-role="th">coef_VaR_2</th>
<th data-quarto-table-cell-role="th">coef_VaR_3</th>
<th data-quarto-table-cell-role="th">coef_VaR_4</th>
<th data-quarto-table-cell-role="th">coef_VaR_5</th>
<th data-quarto-table-cell-role="th">coef_VaR_6</th>
<th data-quarto-table-cell-role="th">coef_VaR_7</th>
<th data-quarto-table-cell-role="th">coef_VaR_8</th>
<th data-quarto-table-cell-role="th">coef_VaR_9</th>
<th data-quarto-table-cell-role="th">coef_VaR_10</th>
<th data-quarto-table-cell-role="th">coef_VaR_11</th>
<th data-quarto-table-cell-role="th">coef_VaR_12</th>
<th data-quarto-table-cell-role="th">coef_VaR_13</th>
<th data-quarto-table-cell-role="th">coef_VaR_14</th>
<th data-quarto-table-cell-role="th">coef_VaR_15</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1e-15</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.8</td>
<td>-6.9</td>
<td>0.83</td>
<td>1.5</td>
<td>1.6</td>
<td>1</td>
<td>0.34</td>
<td>-0.23</td>
<td>-0.57</td>
<td>-0.66</td>
<td>-0.57</td>
<td>-0.35</td>
<td>-0.058</td>
<td>0.27</td>
<td>0.6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_1e-10</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.8</td>
<td>-6.9</td>
<td>0.83</td>
<td>1.5</td>
<td>1.6</td>
<td>1</td>
<td>0.34</td>
<td>-0.23</td>
<td>-0.57</td>
<td>-0.66</td>
<td>-0.57</td>
<td>-0.35</td>
<td>-0.058</td>
<td>0.27</td>
<td>0.6</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1e-08</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.8</td>
<td>-6.9</td>
<td>0.83</td>
<td>1.5</td>
<td>1.6</td>
<td>1</td>
<td>0.34</td>
<td>-0.23</td>
<td>-0.57</td>
<td>-0.66</td>
<td>-0.57</td>
<td>-0.35</td>
<td>-0.058</td>
<td>0.27</td>
<td>0.6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_1e-05</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.8</td>
<td>-6.8</td>
<td>0.73</td>
<td>1.7</td>
<td>1.6</td>
<td>0.93</td>
<td>0.21</td>
<td>0</td>
<td>-0.6</td>
<td>-0.68</td>
<td>-0.55</td>
<td>-0.3</td>
<td>-0</td>
<td>0.023</td>
<td>0.71</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_0.0001</td>
<td>0.02</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.7</td>
<td>-6.5</td>
<td>0</td>
<td>2.8</td>
<td>1.4</td>
<td>0</td>
<td>0</td>
<td>-0</td>
<td>-0</td>
<td>-0.68</td>
<td>-0.43</td>
<td>-0</td>
<td>-0</td>
<td>0</td>
<td>0.35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_0.001</td>
<td>0.024</td>
<td>0.026</td>
<td>-0.072</td>
<td>2</td>
<td>-4.5</td>
<td>-0</td>
<td>0</td>
<td>2.6</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0.37</td>
<td>-0</td>
<td>-0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_0.01</td>
<td>0.084</td>
<td>0.088</td>
<td>-0.072</td>
<td>0.27</td>
<td>-1.3</td>
<td>-0</td>
<td>-0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0.68</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>-0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_0.1</td>
<td>0.19</td>
<td>0.2</td>
<td>-0.072</td>
<td>-0.22</td>
<td>-0.27</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0.12</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1</td>
<td>0.49</td>
<td>0.53</td>
<td>-0.072</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_5</td>
<td>0.49</td>
<td>0.53</td>
<td>-0.072</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="82bfbeb9" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_lasso_reg_coeff(train_x):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> np.logspace(<span class="dv">1</span>,<span class="op">-</span><span class="dv">3</span>,<span class="dv">200</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    coefs <span class="op">=</span> []</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#X_train_std, train_y</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> a <span class="kw">in</span> alphas:        </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>        laso <span class="op">=</span> Lasso(alpha<span class="op">=</span>a, max_iter <span class="op">=</span> <span class="dv">100000</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>        laso.fit(train_x, train_y)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>        coefs.append(laso.coef_)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Visualizing the shrinkage in ridge regression coefficients with increasing values of the tuning parameter lambda</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'xlabel'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'ylabel'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(alphas, coefs)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="vs">r'$\alpha$'</span>)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Standardized coefficient'</span>)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>    plt.legend(train_x.columns )<span class="op">;</span>    </span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>plot_lasso_reg_coeff(X_train_std.iloc[:,:<span class="dv">5</span>])</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">"test1.png"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-36-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="17976656" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>coef_matrix_lasso.<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">sum</span>(x.values<span class="op">==</span><span class="dv">0</span>),axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>alpha_1e-15      0
alpha_1e-10      0
alpha_1e-08      0
alpha_1e-05      2
alpha_0.0001     8
alpha_0.001     11
alpha_0.01      12
alpha_0.1       12
alpha_1         15
alpha_5         15
dtype: int32</code></pre>
</div>
</div>
<div id="f6b5a6f5" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>coef_matrix_lasso[[<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>]].plot()</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Features'</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'MRSS'</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'train'</span>, <span class="st">'test'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-38-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Effect of alpha in Lasso Regression</strong> - <strong>Small alpha (close to 0):</strong> The penalty is minimal, and Lasso behaves like ordinary linear regression. - <strong>Moderate alpha:</strong> Some coefficients shrink, and some become exactly zero, performing feature selection. - <strong>Large alpha:</strong> Many coefficients become zero, leading to a very simple model (potentially underfitting).</p>
</section>
</section>
<section id="elastic-net-regression-combining-l1-and-l2-regularization" class="level3" data-number="10.3.7">
<h3 data-number="10.3.7" class="anchored" data-anchor-id="elastic-net-regression-combining-l1-and-l2-regularization"><span class="header-section-number">10.3.7</span> Elastic Net Regression: Combining L1 and L2 Regularization</h3>
<section id="mathematical-formulation" class="level4" data-number="10.3.7.1">
<h4 data-number="10.3.7.1" class="anchored" data-anchor-id="mathematical-formulation"><span class="header-section-number">10.3.7.1</span> Mathematical Formulation*</h4>
<p>Elastic Net regression combines both <strong>L1 (Lasso) and L2 (Ridge) penalties</strong>, balancing feature selection and coefficient shrinkage. The <strong>regularized loss function</strong> for Elastic Net is given by:</p>
<p><span class="math display">\[
L_{\text{ElasticNet}}(\beta) = \frac{1}{2n} \sum_{i=1}^{n} (y_i - \beta^\top x_i)^2 + \alpha \left( (1 - \rho) \frac{1}{2} \sum_{j=1}^{p} \beta_j^2 + \rho \sum_{j=1}^{p} |\beta_j| \right)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(y_i\)</span> is the true target value for observation <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(x_i\)</span> is the feature vector for observation <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(\beta\)</span> is the vector of model coefficients.</li>
<li><span class="math inline">\(\alpha\)</span> is the <strong>regularization strength</strong> parameter in scikit-learn.</li>
<li><span class="math inline">\(\rho\)</span> is the <strong>l1_ratio</strong> parameter in scikit-learn, controlling the mix of L1 and L2 penalties.</li>
<li><span class="math inline">\(\sum_{j=1}^{p} |\beta_j|\)</span> is the <strong>L1 norm</strong>, enforcing sparsity.</li>
<li><span class="math inline">\(\sum_{j=1}^{p} \beta_j^2\)</span> is the <strong>L2 norm</strong>, ensuring coefficient stability.</li>
</ul>
</section>
<section id="elastic-net-special-cases" class="level4" data-number="10.3.7.2">
<h4 data-number="10.3.7.2" class="anchored" data-anchor-id="elastic-net-special-cases"><span class="header-section-number">10.3.7.2</span> Elastic Net Special Cases</h4>
<ul>
<li>When <strong>l1_ratio = 0</strong>, Elastic Net behaves like <strong>Ridge Regression (L2 regularization)</strong>.</li>
<li>When <strong>l1_ratio = 1</strong>, Elastic Net behaves like <strong>Lasso Regression (L1 regularization)</strong>.</li>
<li>When <strong>0 &lt; l1_ratio &lt; 1</strong>, Elastic Net <strong>balances feature selection (L1) and coefficient shrinkage (L2)</strong>.</li>
</ul>
<p>Now, let’s implement an <strong>Elastic Net Regression model</strong> using <code>scikit-learn</code> and explore how different values of <code>alpha</code> and <code>l1_ratio</code> affect the model.</p>
<div id="46801b39" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> ElasticNet</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>alpha_lasso <span class="op">=</span> [<span class="fl">1e-15</span>, <span class="fl">1e-10</span>, <span class="fl">1e-8</span>, <span class="fl">1e-5</span>,<span class="fl">1e-4</span>, <span class="fl">1e-3</span>,<span class="fl">1e-2</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>]</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>l1_ratio<span class="op">=</span><span class="fl">0.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5b182b4a" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining a function which will fit lasso regression model, plot the results, and return the coefficient</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> elasticnet_regression(train_x, train_y, test_x, test_y, alpha, models_to_plot<span class="op">=</span>{}):</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#fit the model</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> alpha <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> LinearRegression()    </span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> ElasticNet(alpha<span class="op">=</span>alpha, max_iter<span class="op">=</span><span class="dv">20000</span>, l1_ratio<span class="op">=</span>l1_ratio)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    model.fit(train_x, train_y)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    train_y_pred <span class="op">=</span> model.predict(train_x)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    test_y_pred <span class="op">=</span> model.predict(test_x)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#check if a plot is to be made for the entered alpha</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> alpha <span class="kw">in</span> models_to_plot:</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>        plt.subplot(models_to_plot[alpha])</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># plt_tight_layout()</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="op">*</span>sort_xy(train_x.values[:, <span class="dv">0</span>], train_y_pred))</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>        plt.plot(train_x.values[:, <span class="dv">0</span>:<span class="dv">1</span>], train_y, <span class="st">'.'</span>)</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Plot for alpha: </span><span class="sc">%.3g</span><span class="st">'</span><span class="op">%</span>alpha)</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#return the result in pre-defined format</span></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>    mrss_train <span class="op">=</span> <span class="bu">sum</span>((train_y_pred <span class="op">-</span> train_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>train_x.shape[<span class="dv">0</span>]</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>    ret <span class="op">=</span> [mrss_train]</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>    mrss_test <span class="op">=</span> <span class="bu">sum</span>((test_y_pred <span class="op">-</span> test_y)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>test_x.shape[<span class="dv">0</span>]</span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>    ret.extend([mrss_test])</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>    ret.extend([model.intercept_])</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>    ret.extend(model.coef_)</span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ret</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f3877f85" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co">#initialize a dataframe to store the coefficient:</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> [<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>, <span class="st">'intercept'</span>] <span class="op">+</span> [<span class="st">'coef_VaR_</span><span class="sc">%d</span><span class="st">'</span><span class="op">%</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">16</span>)]</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>ind <span class="op">=</span> [<span class="st">'alpha_</span><span class="sc">%.2g</span><span class="st">'</span><span class="op">%</span>alpha_lasso[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>)]</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>coef_matrix_elasticnet <span class="op">=</span> pd.DataFrame(index<span class="op">=</span>ind, columns<span class="op">=</span>col)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="80b9f245" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the number of features for which a plot is required:</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>models_to_plot <span class="op">=</span> {<span class="fl">1e-10</span>:<span class="dv">231</span>, <span class="fl">1e-5</span>:<span class="dv">232</span>,<span class="fl">1e-4</span>:<span class="dv">233</span>, <span class="fl">1e-3</span>:<span class="dv">234</span>, <span class="fl">1e-2</span>:<span class="dv">235</span>, <span class="fl">0.1</span>:<span class="dv">236</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b77b4141" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>models_to_plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>{1e-10: 231, 1e-05: 232, 0.0001: 233, 0.001: 234, 0.01: 235, 0.1: 236}</code></pre>
</div>
</div>
<div id="9c01f29a" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Iterate over the 10 alpha values:</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    coef_matrix_elasticnet.iloc[i,] <span class="op">=</span> elasticnet_regression(X_train_std, train_y, X_test_std, test_y, alpha_lasso[i], models_to_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>c:\Users\lsi8012\AppData\Local\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e-01, tolerance: 1.779e-03
  model = cd_fast.enet_coordinate_descent(
c:\Users\lsi8012\AppData\Local\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e-01, tolerance: 1.779e-03
  model = cd_fast.enet_coordinate_descent(
c:\Users\lsi8012\AppData\Local\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.488e-01, tolerance: 1.779e-03
  model = cd_fast.enet_coordinate_descent(
c:\Users\lsi8012\AppData\Local\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.395e-01, tolerance: 1.779e-03
  model = cd_fast.enet_coordinate_descent(
c:\Users\lsi8012\AppData\Local\anaconda3\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e-02, tolerance: 1.779e-03
  model = cd_fast.enet_coordinate_descent(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-44-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="92dc494a" class="cell" data-scrolled="true" data-execution_count="62">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set the display format to be scientific for ease of analysis</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>pd.options.display.float_format <span class="op">=</span> <span class="st">'</span><span class="sc">{:,.2g}</span><span class="st">'</span>.<span class="bu">format</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>coef_matrix_elasticnet</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mrss_train</th>
<th data-quarto-table-cell-role="th">mrss_test</th>
<th data-quarto-table-cell-role="th">intercept</th>
<th data-quarto-table-cell-role="th">coef_VaR_1</th>
<th data-quarto-table-cell-role="th">coef_VaR_2</th>
<th data-quarto-table-cell-role="th">coef_VaR_3</th>
<th data-quarto-table-cell-role="th">coef_VaR_4</th>
<th data-quarto-table-cell-role="th">coef_VaR_5</th>
<th data-quarto-table-cell-role="th">coef_VaR_6</th>
<th data-quarto-table-cell-role="th">coef_VaR_7</th>
<th data-quarto-table-cell-role="th">coef_VaR_8</th>
<th data-quarto-table-cell-role="th">coef_VaR_9</th>
<th data-quarto-table-cell-role="th">coef_VaR_10</th>
<th data-quarto-table-cell-role="th">coef_VaR_11</th>
<th data-quarto-table-cell-role="th">coef_VaR_12</th>
<th data-quarto-table-cell-role="th">coef_VaR_13</th>
<th data-quarto-table-cell-role="th">coef_VaR_14</th>
<th data-quarto-table-cell-role="th">coef_VaR_15</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1e-15</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.8</td>
<td>-6.9</td>
<td>0.83</td>
<td>1.5</td>
<td>1.6</td>
<td>1</td>
<td>0.34</td>
<td>-0.23</td>
<td>-0.57</td>
<td>-0.66</td>
<td>-0.57</td>
<td>-0.35</td>
<td>-0.058</td>
<td>0.27</td>
<td>0.6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_1e-10</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.8</td>
<td>-6.9</td>
<td>0.83</td>
<td>1.5</td>
<td>1.6</td>
<td>1</td>
<td>0.34</td>
<td>-0.23</td>
<td>-0.57</td>
<td>-0.66</td>
<td>-0.57</td>
<td>-0.35</td>
<td>-0.058</td>
<td>0.27</td>
<td>0.6</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1e-08</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.8</td>
<td>-6.9</td>
<td>0.83</td>
<td>1.5</td>
<td>1.6</td>
<td>1</td>
<td>0.34</td>
<td>-0.23</td>
<td>-0.57</td>
<td>-0.66</td>
<td>-0.57</td>
<td>-0.35</td>
<td>-0.058</td>
<td>0.27</td>
<td>0.6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_1e-05</td>
<td>0.019</td>
<td>0.024</td>
<td>-0.072</td>
<td>2.7</td>
<td>-6.6</td>
<td>0.37</td>
<td>1.7</td>
<td>1.7</td>
<td>1</td>
<td>0.27</td>
<td>-0.13</td>
<td>-0.61</td>
<td>-0.69</td>
<td>-0.57</td>
<td>-0.33</td>
<td>-0.019</td>
<td>0.15</td>
<td>0.66</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_0.0001</td>
<td>0.02</td>
<td>0.023</td>
<td>-0.072</td>
<td>2.4</td>
<td>-5.5</td>
<td>-0.6</td>
<td>1.3</td>
<td>2.2</td>
<td>1.2</td>
<td>0.056</td>
<td>-0</td>
<td>-0.36</td>
<td>-0.83</td>
<td>-0.68</td>
<td>-0.26</td>
<td>-0</td>
<td>0</td>
<td>0.71</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_0.001</td>
<td>0.028</td>
<td>0.03</td>
<td>-0.072</td>
<td>1.6</td>
<td>-3.3</td>
<td>-0.6</td>
<td>0</td>
<td>0.99</td>
<td>1.1</td>
<td>0.54</td>
<td>0</td>
<td>0</td>
<td>-0</td>
<td>-0</td>
<td>-0.21</td>
<td>-0.25</td>
<td>-0.11</td>
<td>-0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_0.01</td>
<td>0.076</td>
<td>0.081</td>
<td>-0.072</td>
<td>0.31</td>
<td>-1.1</td>
<td>-0.48</td>
<td>-0</td>
<td>0</td>
<td>0.14</td>
<td>0.35</td>
<td>0.33</td>
<td>0.14</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>-0</td>
<td>-0</td>
<td>-0.067</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_0.1</td>
<td>0.15</td>
<td>0.16</td>
<td>-0.072</td>
<td>-0.19</td>
<td>-0.41</td>
<td>-0.0068</td>
<td>-0</td>
<td>-0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0.04</td>
<td>0.062</td>
<td>0.073</td>
<td>0.075</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha_1</td>
<td>0.48</td>
<td>0.52</td>
<td>-0.072</td>
<td>-0.013</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">alpha_5</td>
<td>0.49</td>
<td>0.53</td>
<td>-0.072</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
<td>-0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="2bc75e1b" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_elasticnet_reg_coeff(train_x):</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> np.logspace(<span class="dv">1</span>,<span class="op">-</span><span class="dv">3</span>,<span class="dv">200</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    coefs <span class="op">=</span> []</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#X_train_std, train_y</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> a <span class="kw">in</span> alphas:        </span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> ElasticNet(alpha<span class="op">=</span>a, max_iter<span class="op">=</span><span class="dv">20000</span>, l1_ratio<span class="op">=</span>l1_ratio)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>        model.fit(train_x, train_y)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>        coefs.append(model.coef_)</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Visualizing the shrinkage in ridge regression coefficients with increasing values of the tuning parameter lambda</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'xlabel'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'ylabel'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(alphas, coefs)</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>    plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="vs">r'$\alpha$'</span>)</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Standardized coefficient'</span>)</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>    plt.legend(train_x.columns )<span class="op">;</span>    </span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>plot_elasticnet_reg_coeff(X_train_std.iloc[:,:<span class="dv">5</span>])</span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">"test2.png"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-46-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="242d4dfa" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>coef_matrix_elasticnet.<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">sum</span>(x.values<span class="op">==</span><span class="dv">0</span>),axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>alpha_1e-15      0
alpha_1e-10      0
alpha_1e-08      0
alpha_1e-05      0
alpha_0.0001     3
alpha_0.001      6
alpha_0.01       7
alpha_0.1        8
alpha_1         14
alpha_5         15
dtype: int32</code></pre>
</div>
</div>
<div id="d3f597fd" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>coef_matrix_elasticnet[[<span class="st">'mrss_train'</span>, <span class="st">'mrss_test'</span>]].plot()</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Features'</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'MRSS'</span>)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'train'</span>, <span class="st">'test'</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Regularization in Python_files/figure-html/cell-48-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>ElasticNet is controlled by these key parameters:</p>
<ul>
<li><p><strong>alpha</strong> (<code>float</code>, default=<code>1.0</code>):<br>
The regularization strength multiplier. Higher values increase regularization.</p></li>
<li><p><strong>l1_ratio</strong> (<code>float</code>, default=<code>0.5</code>):<br>
The mixing parameter between L1 and L2 penalties:</p>
<ul>
<li><code>l1_ratio = 0</code>: Pure Ridge regression<br>
</li>
<li><code>l1_ratio = 1</code>: Pure Lasso regression<br>
</li>
<li><code>0 &lt; l1_ratio &lt; 1</code>: ElasticNet with mixed penalties</li>
</ul></li>
</ul>
</section>
</section>
<section id="ridgecv-lassocv-and-elasticnetcv-in-scikit-learn" class="level3" data-number="10.3.8">
<h3 data-number="10.3.8" class="anchored" data-anchor-id="ridgecv-lassocv-and-elasticnetcv-in-scikit-learn"><span class="header-section-number">10.3.8</span> <code>RidgeCV</code>, <code>LassoCV</code>, and <code>ElasticNetCV</code> in Scikit-Learn</h3>
<p>In Scikit-Learn, <code>RidgeCV</code>, <code>LassoCV</code>, and <code>ElasticNetCV</code> are cross-validation (CV) versions of <strong>Ridge</strong>, <strong>Lasso</strong>, and <strong>Elastic Net</strong> regression models, respectively. These versions <strong>automatically select the best regularization strength</strong> (<code>alpha</code>) by performing internal cross-validation.</p>
<section id="overview-of-ridgecv-lassocv-and-elasticnetcv" class="level4" data-number="10.3.8.1">
<h4 data-number="10.3.8.1" class="anchored" data-anchor-id="overview-of-ridgecv-lassocv-and-elasticnetcv"><span class="header-section-number">10.3.8.1</span> Overview of RidgeCV, LassoCV, and ElasticNetCV**</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 21%">
<col style="width: 52%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Regularization Type</th>
<th>Purpose</th>
<th>How Alpha is Chosen?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>RidgeCV</strong></td>
<td>L2 (Ridge)</td>
<td>Shrinks coefficients to handle overfitting, but keeps all features.</td>
<td>Uses cross-validation to select the best <code>alpha</code>.</td>
</tr>
<tr class="even">
<td><strong>LassoCV</strong></td>
<td>L1 (Lasso)</td>
<td>Shrinks coefficients, but also <strong>removes</strong> some features by setting coefficients to zero.</td>
<td>Uses cross-validation to find the best <code>alpha</code>.</td>
</tr>
<tr class="odd">
<td><strong>ElasticNetCV</strong></td>
<td>L1 + L2 (Elastic Net)</td>
<td>Balances Ridge and Lasso.</td>
<td>Uses cross-validation to find the best <code>alpha</code> and <code>l1_ratio</code>.</td>
</tr>
</tbody>
</table>
</section>
<section id="how-to-use-ridgecv-lassocv-andelasticnetcv" class="level4" data-number="10.3.8.2">
<h4 data-number="10.3.8.2" class="anchored" data-anchor-id="how-to-use-ridgecv-lassocv-andelasticnetcv"><span class="header-section-number">10.3.8.2</span> How to Use <code>RidgeCV</code>, <code>LassoCV</code>, and<code>ElasticNetCV</code></h4>
<p>Each model automatically selects the optimal <code>alpha</code> value through internal cross-validation without using a loop through the <code>alpha</code> values</p>
<div id="3aa93cc6" class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LassoCV</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>alpha_lasso <span class="op">=</span> [<span class="fl">1e-15</span>, <span class="fl">1e-10</span>, <span class="fl">1e-8</span>, <span class="fl">1e-5</span>, <span class="fl">1e-4</span>, <span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>]</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize LassoCV with cross-validation</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="op">=</span> LassoCV(alphas<span class="op">=</span>alpha_lasso, cv<span class="op">=</span><span class="dv">5</span>, max_iter<span class="op">=</span><span class="dv">2000000</span>)</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using training data</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>lasso_cv.fit(X_train_std, train_y)</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>train_y_pred <span class="op">=</span> lasso_cv.predict(X_train_std)</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>test_y_pred <span class="op">=</span> lasso_cv.predict(X_test_std)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best alpha chosen by cross-validation</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>best_alpha <span class="op">=</span> lasso_cv.alpha_</span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best alpha selected by LassoCV: </span><span class="sc">{</span>best_alpha<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if a plot should be made for the selected alpha</span></span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_alpha <span class="kw">in</span> models_to_plot:</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>    plt.subplot(models_to_plot[best_alpha])</span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="op">*</span>sort_xy(train_x[:, <span class="dv">0</span>], train_y_pred))</span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>    plt.plot(train_x[:, <span class="dv">0</span>:<span class="dv">1</span>], train_y, <span class="st">'.'</span>, label<span class="op">=</span><span class="st">"Actual Data"</span>)</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Plot for alpha: </span><span class="sc">{</span>best_alpha<span class="sc">:.3g}</span><span class="ss">'</span>)</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>    plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="reference" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="reference"><span class="header-section-number">10.4</span> Reference</h2>
<p>https://www.linkedin.com/pulse/tutorial-ridge-lasso-regression-subhajit-mondal/?trk=read_related_article-card_title</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./cross_validation.html" class="pagination-link" aria-label="Cross-Validation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Cross-Validation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Feature Selection.html" class="pagination-link" aria-label="Feature Selection">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Feature Selection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>